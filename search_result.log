 - _log_softmax
  - _log_softmax
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:569:Tensor special_log_softmax(const Tensor& input, const int64_t dim, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:636:static Tensor _sparse_log_softmax(const Tensor& input_, const int64_t dim_) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:645:Tensor _sparse_log_softmax(const Tensor& input_, const int64_t dim_, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:659:Tensor _sparse_log_softmax(const Tensor& self, Dimname dim, optional<ScalarType> dtype) {


 - _native_batch_norm_legit.no_stats
  - _native_batch_norm_legit

  - _batch_norm_legit_no_stats_cpu(CPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Normalization.cpp:804:std::tuple<Tensor, Tensor, Tensor> _batch_norm_legit_no_stats_cpu(
  - _batch_norm_legit_no_stats_cuda(CUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Normalization.cu:480:std::tuple<Tensor, Tensor, Tensor> _batch_norm_legit_no_stats_cuda(const Tensor& self, const c10::optional<Tensor>& weight_opt, const c10::optional<Tensor>& bias_opt, bool train, double momentum, double epsilon) {
  - _batch_norm_legit_no_stats_mps(MPS)
  - _mkldnn_batch_norm_legit_no_stats(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Normalization.cpp:54:std::tuple<Tensor, Tensor, Tensor> _mkldnn_batch_norm_legit_no_stats(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Normalization.cpp:204:std::tuple<Tensor, Tensor, Tensor> _mkldnn_batch_norm_legit_no_stats(


 - _softmax
  - _softmax
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:685:inline void _vec_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:792:inline void _vec_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:1131:      _vec_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:154:void host_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:505:Tensor special_softmax(const Tensor& input_, const int64_t dim_, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:509:static Tensor log_softmax(const Tensor& input_, const int64_t dim_) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:518:Tensor log_softmax(const Tensor& input_, const int64_t dim_, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:569:Tensor special_log_softmax(const Tensor& input, const int64_t dim, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:587:Tensor log_softmax(const Tensor& self, Dimname dim, optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LossNLL.cpp:644:        at::log_softmax(self, class_dim, self.scalar_type()),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Softmax.cpp:147:Tensor log_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:158:void cpu_sparse_coo_softmax(Tensor output, const Tensor& input, const int64_t dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:609:static Tensor _sparse_softmax(const Tensor& input_, const int64_t dim_) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:618:Tensor _sparse_softmax(const Tensor& input_, const int64_t dim_, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:632:Tensor _sparse_softmax(const Tensor& self, Dimname dim, optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:636:static Tensor _sparse_log_softmax(const Tensor& input_, const int64_t dim_) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:645:Tensor _sparse_log_softmax(const Tensor& input_, const int64_t dim_, c10::optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:659:Tensor _sparse_log_softmax(const Tensor& self, Dimname dim, optional<ScalarType> dtype) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/SoftMax.cu:385:void cuda_sparse_coo_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/SoftMax.cpp:16:Tensor mkldnn_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/SoftMax.cpp:33:Tensor mkldnn_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/SoftMax.cu:716:Tensor host_softmax(const Tensor & input_, const int64_t dim_, const bool half_to_float, const Tensor& output){
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/attention.cpp:141:Tensor masked_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/attention.h:17:TORCH_API Tensor masked_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:1116:  CUTLASS_DEVICE static void iterative_softmax(
  - mkldnn_softmax(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/SoftMax.cpp:16:Tensor mkldnn_softmax(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/SoftMax.cpp:33:Tensor mkldnn_softmax(
  - softmax_nested(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorMath.cpp:499:Tensor softmax_nested(


 - _to_copy
  - _to_copy
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:225:Tensor _to_copy(
   - /home/haozhe/code/pytorch/aten/src/ATen/FunctionalTensorWrapper.cpp:226:    // and we want _to_copy() to show up in the graph, not the composite .to() operator
  - _to_copy(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:225:Tensor _to_copy(
   - /home/haozhe/code/pytorch/aten/src/ATen/FunctionalTensorWrapper.cpp:226:    // and we want _to_copy() to show up in the graph, not the composite .to() operator
  - _to_copy_nested(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorFactories.cpp:84:Tensor _to_copy_nested(


 - abs
  - abs
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:233:  Vectorized<ComplexDbl> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_int64_vsx.h:188:  Vectorized<int64_t> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:281:  Vectorized<ComplexFlt> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_int16_vsx.h:305:  Vectorized<int16_t> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_int32_vsx.h:236:  Vectorized<int32_t> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:215:  Vectorized<double> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:254:  Vectorized<float> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:319:  Vectorized<float> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:121:  Vectorized<int64_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:243:  Vectorized<int32_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:456:  Vectorized<int16_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:740:  Vectorized<int8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:778:  Vectorized<uint8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:164:  Vectorized<c10::complex<float>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:276:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:850:  Vectorized<U> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:857:  Vectorized<U> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2418:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:112:  Vectorized<double> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:118:  Vectorized<float> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:129:  Vectorized<c10::complex<double>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:276:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:283:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:292:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:123:  Vectorized<int64_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:275:  Vectorized<int32_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:506:  Vectorized<int16_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:820:  Vectorized<int8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:869:  Vectorized<uint8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:356:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:182:  Vectorized<c10::complex<double>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:687:  Vectorized<c10::complex<float>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:144:  Vectorized<float> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:129:  Vectorized<double> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:930:              m0 + (a0 - b0).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:934:              m1 + (a1 - b1).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:963:                m + (a - b).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:995:              m0 + (a0 - b0).abs().neg().exp2().log1p() * inv_log_2_vec,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:999:              m1 + (a1 - b1).abs().neg().exp2().log1p() * inv_log_2_vec,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:1022:                m + (a - b).abs().neg().exp2().log1p() * inv_log_2_vec,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp:21:  // that are much faster than std::pow(std::abs(a - b), p), but have the same
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp:51:  static inline Vec abs(Vec val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp:55:  static inline scalar_t abs(scalar_t val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Clamp.cpp:460:Tensor abs(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Lerp.h:16:  // Avoid the sqrt in abs(weight)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:516:    // For Hermitian matrices, singular values equal to abs(eigenvalues)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:518:    // eigenvalues are sorted in ascending order starting with negative values, we need a maximum value of abs(eigenvalues)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:600: * matrix will be raised to power abs(n).
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:638:  // For negative n we inverte the input matrix before raising to power abs(n)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:734:    // eigenvalues are sorted in ascending order starting with negative values, we need a maximum value of abs(eigenvalues)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2664:  // results to the std::abs(std::complex<T>) implementation.
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2665:  // As such, to be able to compute the correct index in the backward, we need to use self.abs()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/UnaryOps.cpp:549:Tensor abs(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorUnaryOps.cpp:21:Tensor NestedTensor_abs(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:48:                    - ::abs(output_x - (input_w + pad_l - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:79:                 - ::abs(output_x - (input_dim_x + pad_l - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:85:                 - ::abs(output_y - (input_dim_y + pad_t - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:191:                 - ::abs(output_x - (input.size(4) + pad_left - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:196:                 - ::abs(output_y - (input.size(3) + pad_top - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:202:                 - ::abs(output_z - (input.size(2) + pad_front - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/requantization-tester.h:376:        ASSERT_LE(fabs(referenceOutput - double(outputs[i])), 0.55)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/fully-connected-operator-tester.h:365:                  std::abs(ref) * 1.0e-4)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:450:              std::abs(acc[mIndex * n() + nIndex]) * 1.0e-4f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:893:              std::abs(cRef[mIndex * n() + nIndex]) * 1.0e-2f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:995:              std::abs(cRef[mIndex * n() + nIndex]) * 1.0e-6f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:1138:              std::abs(cRef[mIndex * n() + nIndex]) * 1.0e-6f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-block-sparse-microkernel-tester.h:484:              std::abs(acc[mIndex * n() + nIndex]) * 1.0e-3f)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vulkan_quantized_api_test.cpp:1836:          input2_cpu.sign() - input2_cpu.sign().abs() + 1;
   - /home/haozhe/code/pytorch/aten/src/ATen/test/cuda_complex_math_test.cu:20:#define C10_ASSERT_NEAR(a, b, tol) assert(abs(a - b) < tol)
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:580:abs(const complex<_Tp>& __c)
  - abs(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:233:  Vectorized<ComplexDbl> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_int64_vsx.h:188:  Vectorized<int64_t> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:281:  Vectorized<ComplexFlt> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_int16_vsx.h:305:  Vectorized<int16_t> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_int32_vsx.h:236:  Vectorized<int32_t> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:215:  Vectorized<double> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:254:  Vectorized<float> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:319:  Vectorized<float> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:121:  Vectorized<int64_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:243:  Vectorized<int32_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:456:  Vectorized<int16_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:740:  Vectorized<int8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:778:  Vectorized<uint8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:164:  Vectorized<c10::complex<float>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:276:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:850:  Vectorized<U> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:857:  Vectorized<U> C10_ALWAYS_INLINE abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2418:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:112:  Vectorized<double> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:118:  Vectorized<float> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:129:  Vectorized<c10::complex<double>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:276:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:283:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:292:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:123:  Vectorized<int64_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:275:  Vectorized<int32_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:506:  Vectorized<int16_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:820:  Vectorized<int8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:869:  Vectorized<uint8_t> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:356:  Vectorized<T> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:182:  Vectorized<c10::complex<double>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:687:  Vectorized<c10::complex<float>> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:144:  Vectorized<float> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:129:  Vectorized<double> abs() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:930:              m0 + (a0 - b0).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:934:              m1 + (a1 - b1).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:963:                m + (a - b).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:995:              m0 + (a0 - b0).abs().neg().exp2().log1p() * inv_log_2_vec,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:999:              m1 + (a1 - b1).abs().neg().exp2().log1p() * inv_log_2_vec,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:1022:                m + (a - b).abs().neg().exp2().log1p() * inv_log_2_vec,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp:21:  // that are much faster than std::pow(std::abs(a - b), p), but have the same
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp:51:  static inline Vec abs(Vec val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistanceOpsKernel.cpp:55:  static inline scalar_t abs(scalar_t val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Clamp.cpp:460:Tensor abs(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Lerp.h:16:  // Avoid the sqrt in abs(weight)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:516:    // For Hermitian matrices, singular values equal to abs(eigenvalues)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:518:    // eigenvalues are sorted in ascending order starting with negative values, we need a maximum value of abs(eigenvalues)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:600: * matrix will be raised to power abs(n).
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:638:  // For negative n we inverte the input matrix before raising to power abs(n)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:734:    // eigenvalues are sorted in ascending order starting with negative values, we need a maximum value of abs(eigenvalues)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2664:  // results to the std::abs(std::complex<T>) implementation.
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2665:  // As such, to be able to compute the correct index in the backward, we need to use self.abs()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/UnaryOps.cpp:549:Tensor abs(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorUnaryOps.cpp:21:Tensor NestedTensor_abs(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:48:                    - ::abs(output_x - (input_w + pad_l - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:79:                 - ::abs(output_x - (input_dim_x + pad_l - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:85:                 - ::abs(output_y - (input_dim_y + pad_t - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:191:                 - ::abs(output_x - (input.size(4) + pad_left - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:196:                 - ::abs(output_y - (input.size(3) + pad_top - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:202:                 - ::abs(output_z - (input.size(2) + pad_front - 1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/requantization-tester.h:376:        ASSERT_LE(fabs(referenceOutput - double(outputs[i])), 0.55)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/fully-connected-operator-tester.h:365:                  std::abs(ref) * 1.0e-4)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:450:              std::abs(acc[mIndex * n() + nIndex]) * 1.0e-4f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:893:              std::abs(cRef[mIndex * n() + nIndex]) * 1.0e-2f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:995:              std::abs(cRef[mIndex * n() + nIndex]) * 1.0e-6f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-microkernel-tester.h:1138:              std::abs(cRef[mIndex * n() + nIndex]) * 1.0e-6f)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/gemm-block-sparse-microkernel-tester.h:484:              std::abs(acc[mIndex * n() + nIndex]) * 1.0e-3f)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vulkan_quantized_api_test.cpp:1836:          input2_cpu.sign() - input2_cpu.sign().abs() + 1;
   - /home/haozhe/code/pytorch/aten/src/ATen/test/cuda_complex_math_test.cu:20:#define C10_ASSERT_NEAR(a, b, tol) assert(abs(a - b) < tol)
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:580:abs(const complex<_Tp>& __c)
  - abs_sparse(SparseCPU, SparseCUDA)
  - abs_sparse_csr(SparseCsrCPU, SparseCsrCUDA)
  - NestedTensor_abs(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorUnaryOps.cpp:21:Tensor NestedTensor_abs(const Tensor& self) {


 - acos
  - acos
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:309:  Vectorized<ComplexDbl> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:453:  Vectorized<ComplexFlt> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:219:  Vectorized<double> C10_ALWAYS_INLINE acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:258:  Vectorized<float> C10_ALWAYS_INLINE acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:337:  Vectorized<float> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:246:  Vectorized<c10::complex<float>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:307:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1039:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2319:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:137:  Vectorized<double> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:143:  Vectorized<float> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:210:  Vectorized<c10::complex<double>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:361:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:390:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:271:  Vectorized<c10::complex<double>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:777:  Vectorized<c10::complex<float>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:172:  Vectorized<float> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:157:  Vectorized<double> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalNeuronType.h:54:API_AVAILABLE(ios(11.3), macos(10.13), macCatalyst(13.0))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNFullyConnectedOp.h:7:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNNeuronOp.h:12:API_AVAILABLE(ios(11.3), macos(10.13), macCatalyst(13.0))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSImageWrapper.h:12:class API_AVAILABLE(ios(11.0), macos(10.13)) MPSImageWrapper {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNUtils.h:34:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNUtils.h:39:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNUtils.h:47:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNConvOp.h:6:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNConvOp.h:18:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalContext.h:6:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:1071:acos(const complex<_Tp>& __x)


 - acosh
  - acosh
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:938:acosh(const complex<_Tp>& __x)


 - add.Scalar
  - add
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:192:  Vectorized<ComplexDbl> el_madd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:196:        vec_madd(_vec0, multiplier._vec0, val._vec0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:197:        vec_madd(_vec1, multiplier._vec1, val._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:381:  static Vectorized<ComplexDbl> horizontal_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint32_vsx.h:120:        vec_madd(scale_vec0, float_vals0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint32_vsx.h:121:        vec_madd(scale_vec1, float_vals1, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:37:Vectorized<double> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:42:      vec_madd(a.vec0(), b.vec0(), c.vec0()),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:43:      vec_madd(a.vec1(), b.vec1(), c.vec1())};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:47:Vectorized<int64_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:55:Vectorized<int32_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:63:Vectorized<int16_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:151:            vec_madd(scale_vec0, vecf0_0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:152:            vec_madd(scale_vec1, vecf1_0, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:154:            vec_madd(scale_vec0, vecf0_1, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:155:            vec_madd(scale_vec1, vecf1_1, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:157:            vec_madd(scale_vec0, vecf0_2, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:158:            vec_madd(scale_vec1, vecf1_2, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:160:            vec_madd(scale_vec0, vecf0_3, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:161:            vec_madd(scale_vec1, vecf1_3, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:344:  Vectorized<ComplexFlt> el_madd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:348:        vec_madd(_vec0, multiplier._vec0, val._vec0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:349:        vec_madd(_vec1, multiplier._vec1, val._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:162:            vec_madd(scale_vec0, vecf0_0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:163:            vec_madd(scale_vec1, vecf1_0, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:165:            vec_madd(scale_vec0, vecf0_1, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:166:            vec_madd(scale_vec1, vecf1_1, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:168:            vec_madd(scale_vec0, vecf0_2, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:169:            vec_madd(scale_vec1, vecf1_2, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:171:            vec_madd(scale_vec0, vecf0_3, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:172:            vec_madd(scale_vec1, vecf1_3, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:830:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:775:Vectorized<BFloat16> inline fmadd(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:973:Vectorized<Half> inline fmadd(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1409:Vectorized<float> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1418:Vectorized<double> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1427:Vectorized<int16_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1435:Vectorized<int32_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1443:Vectorized<int64_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1738:        fmadd(scale, vecf_0, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1739:        fmadd(scale, vecf_1, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1740:        fmadd(scale, vecf_2, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1741:        fmadd(scale, vecf_3, scale_zp_premul)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:415:Vectorized<double> inline fmadd(const Vectorized<double>& a, const Vectorized<double>& b, const Vectorized<double>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:450:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:890:inline Vectorized<T> fmadd(const Vectorized<T>& a, const Vectorized<T>& b, const Vectorized<T>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:894:Vectorized<BFloat16> inline fmadd(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:1105:Vectorized<Half> inline fmadd(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:496:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:452:Vectorized<double> inline fmadd(const Vectorized<double>& a, const Vectorized<double>& b, const Vectorized<double>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchedTensorImpl.cpp:18:      key_set.add(DispatchKey::FuncTorchBatched),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:16:static inline void cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:78:                  cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:101:                cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:151:              cadd(dst_slice,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:165:            cadd(dst_slice,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp:442:mask_scatter_add(const scalar_t *src, scalar_t* base_addr,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp:803:        mask_scatter_add(gOut_slice[c].data() + offset, (*gInp_slice_ptr)[c].data(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ufunc/add.h:15:C10_HOST_DEVICE C10_ALWAYS_INLINE T add(T self, T other, T alpha) __ubsan_ignore_undefined__ {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ufunc/add.h:22:C10_ALWAYS_INLINE Vectorized<T> add(Vectorized<T> self, Vectorized<T> other, Vectorized<T> alpha) __ubsan_ignore_undefined__ {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:118:index_select_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:201:index_select_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:381:index_select_add(const Tensor &select_indices,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:510:index_select_scale_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:570:index_select_scale_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:761:index_select_scale_add(const Tensor &select_indices,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:90:kernel void elementwise_add(texture2d_array<half, access::read> in0[[texture(0)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/QuantizedFunctions.h:22:Tensor quantized_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp:258:      TORCH_SELECTIVE_SCHEMA("vulkan_quantized::add(Tensor qa, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Arithmetic.cpp:433:Tensor quantized_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:339:Tensor index_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source, const Scalar &alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:384:Tensor scatter_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseFactories.cpp:56:      offsets_1d.add(shape[0]).clamp_max_(diagonals_2d.size(1)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:28:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:101:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ForeachUtils.h:159:      // `_foreach_add(bool_tensors, bool_tensors)` being pushed to slow path.
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1835:        .unsqueeze_(-1).add(block_coo_indices.unsqueeze_(1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:1117:at::Tensor PackedConvWeightsOnednn<kSpatialDim>::apply_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/OnednnUtils.h:274:  at::Tensor apply_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:138:Tensor qnnpack_add(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:141:                "qnnpack_add(): Expected both input data types to be ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:283:Tensor xnnp_add(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:376:Tensor qadd(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:486:static Tensor quantized_add(Tensor qa, Tensor qb, double scale, int64_t zero_point){
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gmem_tile.h:260:    inline __device__ void atomic_add(const uint4 (&src)[STGS_PER_LOOP], int mi) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cudnn/BinaryOps.cpp:90:Tensor add(Tensor qa, Tensor qb, double output_scale, int64_t output_zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:542:static inline __device__ uint16_t hadd(uint16_t a, uint16_t b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:555:static inline __device__ uint32_t hadd(uint32_t a, uint32_t b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:570:static inline __device__ uint2 hadd(uint2 a, uint2 b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:649:static inline __device__ uint4 hadd(uint4 a, uint4 b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gemm.h:128:    inline __device__ void add(const Fragment &other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gemm.h:175:    inline __device__ void add(const Other_fragment_ &other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1161:Tensor add(const Tensor& self, const Scalar& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/benchmarks/tensor_add.cpp:5:static void tensor_add(benchmark::State& state) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:18:  _(+, x.add(y), y.add(x))                                                  \
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2086:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2087:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2109:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2110:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2134:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2135:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/boxing/impl/kernel_stackbased_test.cpp:193:                                    .add(c10::DispatchKey::TESTING_ONLY_GenericWrapper)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/cuda_atomic_ops_test.cu:48:void test_atomic_add() {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:570:    TestSeed add(uint64_t index) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:1119:    not_inline float add(float a, float b)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:1123:    not_inline double add(double a, double b)
  - add(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/mkl/SparseBlas.cpp:168:  TORCH_MKLSPARSE_CHECK(mkl_sparse_c_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/mkl/SparseBlas.cpp:173:  TORCH_MKLSPARSE_CHECK(mkl_sparse_z_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/mkl/SparseBlas.h:97:inline void add(MKL_SPARSE_ADD_ARGTYPES(scalar_t)) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:192:  Vectorized<ComplexDbl> el_madd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:196:        vec_madd(_vec0, multiplier._vec0, val._vec0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:197:        vec_madd(_vec1, multiplier._vec1, val._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:381:  static Vectorized<ComplexDbl> horizontal_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint32_vsx.h:120:        vec_madd(scale_vec0, float_vals0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint32_vsx.h:121:        vec_madd(scale_vec1, float_vals1, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:37:Vectorized<double> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:42:      vec_madd(a.vec0(), b.vec0(), c.vec0()),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:43:      vec_madd(a.vec1(), b.vec1(), c.vec1())};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:47:Vectorized<int64_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:55:Vectorized<int32_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:63:Vectorized<int16_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:151:            vec_madd(scale_vec0, vecf0_0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:152:            vec_madd(scale_vec1, vecf1_0, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:154:            vec_madd(scale_vec0, vecf0_1, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:155:            vec_madd(scale_vec1, vecf1_1, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:157:            vec_madd(scale_vec0, vecf0_2, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:158:            vec_madd(scale_vec1, vecf1_2, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:160:            vec_madd(scale_vec0, vecf0_3, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:161:            vec_madd(scale_vec1, vecf1_3, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:344:  Vectorized<ComplexFlt> el_madd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:348:        vec_madd(_vec0, multiplier._vec0, val._vec0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:349:        vec_madd(_vec1, multiplier._vec1, val._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:162:            vec_madd(scale_vec0, vecf0_0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:163:            vec_madd(scale_vec1, vecf1_0, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:165:            vec_madd(scale_vec0, vecf0_1, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:166:            vec_madd(scale_vec1, vecf1_1, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:168:            vec_madd(scale_vec0, vecf0_2, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:169:            vec_madd(scale_vec1, vecf1_2, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:171:            vec_madd(scale_vec0, vecf0_3, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:172:            vec_madd(scale_vec1, vecf1_3, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:830:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:775:Vectorized<BFloat16> inline fmadd(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:973:Vectorized<Half> inline fmadd(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1409:Vectorized<float> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1418:Vectorized<double> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1427:Vectorized<int16_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1435:Vectorized<int32_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1443:Vectorized<int64_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1738:        fmadd(scale, vecf_0, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1739:        fmadd(scale, vecf_1, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1740:        fmadd(scale, vecf_2, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1741:        fmadd(scale, vecf_3, scale_zp_premul)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:415:Vectorized<double> inline fmadd(const Vectorized<double>& a, const Vectorized<double>& b, const Vectorized<double>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:450:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:890:inline Vectorized<T> fmadd(const Vectorized<T>& a, const Vectorized<T>& b, const Vectorized<T>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:894:Vectorized<BFloat16> inline fmadd(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:1105:Vectorized<Half> inline fmadd(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:496:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:452:Vectorized<double> inline fmadd(const Vectorized<double>& a, const Vectorized<double>& b, const Vectorized<double>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchedTensorImpl.cpp:18:      key_set.add(DispatchKey::FuncTorchBatched),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:16:static inline void cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:78:                  cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:101:                cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:151:              cadd(dst_slice,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:165:            cadd(dst_slice,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp:442:mask_scatter_add(const scalar_t *src, scalar_t* base_addr,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp:803:        mask_scatter_add(gOut_slice[c].data() + offset, (*gInp_slice_ptr)[c].data(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ufunc/add.h:15:C10_HOST_DEVICE C10_ALWAYS_INLINE T add(T self, T other, T alpha) __ubsan_ignore_undefined__ {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ufunc/add.h:22:C10_ALWAYS_INLINE Vectorized<T> add(Vectorized<T> self, Vectorized<T> other, Vectorized<T> alpha) __ubsan_ignore_undefined__ {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:118:index_select_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:201:index_select_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:381:index_select_add(const Tensor &select_indices,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:510:index_select_scale_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:570:index_select_scale_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:761:index_select_scale_add(const Tensor &select_indices,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:90:kernel void elementwise_add(texture2d_array<half, access::read> in0[[texture(0)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/QuantizedFunctions.h:22:Tensor quantized_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp:258:      TORCH_SELECTIVE_SCHEMA("vulkan_quantized::add(Tensor qa, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Arithmetic.cpp:433:Tensor quantized_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:339:Tensor index_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source, const Scalar &alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:384:Tensor scatter_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseFactories.cpp:56:      offsets_1d.add(shape[0]).clamp_max_(diagonals_2d.size(1)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:28:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:101:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ForeachUtils.h:159:      // `_foreach_add(bool_tensors, bool_tensors)` being pushed to slow path.
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1835:        .unsqueeze_(-1).add(block_coo_indices.unsqueeze_(1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:1117:at::Tensor PackedConvWeightsOnednn<kSpatialDim>::apply_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/OnednnUtils.h:274:  at::Tensor apply_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:138:Tensor qnnpack_add(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:141:                "qnnpack_add(): Expected both input data types to be ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:283:Tensor xnnp_add(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:376:Tensor qadd(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:486:static Tensor quantized_add(Tensor qa, Tensor qb, double scale, int64_t zero_point){
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cudnn/BinaryOps.cpp:90:Tensor add(Tensor qa, Tensor qb, double output_scale, int64_t output_zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gmem_tile.h:260:    inline __device__ void atomic_add(const uint4 (&src)[STGS_PER_LOOP], int mi) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:542:static inline __device__ uint16_t hadd(uint16_t a, uint16_t b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:555:static inline __device__ uint32_t hadd(uint32_t a, uint32_t b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:570:static inline __device__ uint2 hadd(uint2 a, uint2 b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:649:static inline __device__ uint4 hadd(uint4 a, uint4 b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gemm.h:128:    inline __device__ void add(const Fragment &other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gemm.h:175:    inline __device__ void add(const Other_fragment_ &other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1161:Tensor add(const Tensor& self, const Scalar& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/benchmarks/tensor_add.cpp:5:static void tensor_add(benchmark::State& state) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:18:  _(+, x.add(y), y.add(x))                                                  \
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2086:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2087:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2109:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2110:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2134:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2135:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/boxing/impl/kernel_stackbased_test.cpp:193:                                    .add(c10::DispatchKey::TESTING_ONLY_GenericWrapper)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/cuda_atomic_ops_test.cu:48:void test_atomic_add() {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:570:    TestSeed add(uint64_t index) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:1119:    not_inline float add(float a, float b)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:1123:    not_inline double add(double a, double b)


 - add.Tensor
  - add
   - /home/haozhe/code/pytorch/aten/src/ATen/mkl/SparseBlas.cpp:168:  TORCH_MKLSPARSE_CHECK(mkl_sparse_c_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/mkl/SparseBlas.cpp:173:  TORCH_MKLSPARSE_CHECK(mkl_sparse_z_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/mkl/SparseBlas.h:97:inline void add(MKL_SPARSE_ADD_ARGTYPES(scalar_t)) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:192:  Vectorized<ComplexDbl> el_madd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:196:        vec_madd(_vec0, multiplier._vec0, val._vec0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:197:        vec_madd(_vec1, multiplier._vec1, val._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:381:  static Vectorized<ComplexDbl> horizontal_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint32_vsx.h:120:        vec_madd(scale_vec0, float_vals0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint32_vsx.h:121:        vec_madd(scale_vec1, float_vals1, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:37:Vectorized<double> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:42:      vec_madd(a.vec0(), b.vec0(), c.vec0()),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:43:      vec_madd(a.vec1(), b.vec1(), c.vec1())};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:47:Vectorized<int64_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:55:Vectorized<int32_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_common_vsx.h:63:Vectorized<int16_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:151:            vec_madd(scale_vec0, vecf0_0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:152:            vec_madd(scale_vec1, vecf1_0, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:154:            vec_madd(scale_vec0, vecf0_1, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:155:            vec_madd(scale_vec1, vecf1_1, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:157:            vec_madd(scale_vec0, vecf0_2, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:158:            vec_madd(scale_vec1, vecf1_2, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:160:            vec_madd(scale_vec0, vecf0_3, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_qint8_vsx.h:161:            vec_madd(scale_vec1, vecf1_3, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:344:  Vectorized<ComplexFlt> el_madd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:348:        vec_madd(_vec0, multiplier._vec0, val._vec0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:349:        vec_madd(_vec1, multiplier._vec1, val._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:162:            vec_madd(scale_vec0, vecf0_0, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:163:            vec_madd(scale_vec1, vecf1_0, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:165:            vec_madd(scale_vec0, vecf0_1, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:166:            vec_madd(scale_vec1, vecf1_1, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:168:            vec_madd(scale_vec0, vecf0_2, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:169:            vec_madd(scale_vec1, vecf1_2, scale_zp_premul1)},
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:171:            vec_madd(scale_vec0, vecf0_3, scale_zp_premul0),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_quint8_vsx.h:172:            vec_madd(scale_vec1, vecf1_3, scale_zp_premul1)}};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:830:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:775:Vectorized<BFloat16> inline fmadd(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:973:Vectorized<Half> inline fmadd(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1409:Vectorized<float> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1418:Vectorized<double> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1427:Vectorized<int16_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1435:Vectorized<int32_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1443:Vectorized<int64_t> C10_ALWAYS_INLINE fmadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1738:        fmadd(scale, vecf_0, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1739:        fmadd(scale, vecf_1, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1740:        fmadd(scale, vecf_2, scale_zp_premul),
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1741:        fmadd(scale, vecf_3, scale_zp_premul)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:415:Vectorized<double> inline fmadd(const Vectorized<double>& a, const Vectorized<double>& b, const Vectorized<double>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:450:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:890:inline Vectorized<T> fmadd(const Vectorized<T>& a, const Vectorized<T>& b, const Vectorized<T>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:894:Vectorized<BFloat16> inline fmadd(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:1105:Vectorized<Half> inline fmadd(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:496:Vectorized<float> inline fmadd(const Vectorized<float>& a, const Vectorized<float>& b, const Vectorized<float>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:452:Vectorized<double> inline fmadd(const Vectorized<double>& a, const Vectorized<double>& b, const Vectorized<double>& c) {
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchedTensorImpl.cpp:18:      key_set.add(DispatchKey::FuncTorchBatched),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:16:static inline void cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:78:                  cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:101:                cadd(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:151:              cadd(dst_slice,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Unfold2d.cpp:165:            cadd(dst_slice,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp:442:mask_scatter_add(const scalar_t *src, scalar_t* base_addr,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/GridSamplerKernel.cpp:803:        mask_scatter_add(gOut_slice[c].data() + offset, (*gInp_slice_ptr)[c].data(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ufunc/add.h:15:C10_HOST_DEVICE C10_ALWAYS_INLINE T add(T self, T other, T alpha) __ubsan_ignore_undefined__ {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ufunc/add.h:22:C10_ALWAYS_INLINE Vectorized<T> add(Vectorized<T> self, Vectorized<T> other, Vectorized<T> alpha) __ubsan_ignore_undefined__ {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:118:index_select_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:201:index_select_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:381:index_select_add(const Tensor &select_indices,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:510:index_select_scale_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:570:index_select_scale_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/EmbeddingBag.cpp:761:index_select_scale_add(const Tensor &select_indices,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:90:kernel void elementwise_add(texture2d_array<half, access::read> in0[[texture(0)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/QuantizedFunctions.h:22:Tensor quantized_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp:258:      TORCH_SELECTIVE_SCHEMA("vulkan_quantized::add(Tensor qa, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Arithmetic.cpp:433:Tensor quantized_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:339:Tensor index_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source, const Scalar &alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:384:Tensor scatter_add(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseFactories.cpp:56:      offsets_1d.add(shape[0]).clamp_max_(diagonals_2d.size(1)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:28:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:101:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ForeachUtils.h:159:      // `_foreach_add(bool_tensors, bool_tensors)` being pushed to slow path.
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1835:        .unsqueeze_(-1).add(block_coo_indices.unsqueeze_(1))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qconv.cpp:1117:at::Tensor PackedConvWeightsOnednn<kSpatialDim>::apply_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/OnednnUtils.h:274:  at::Tensor apply_add(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:138:Tensor qnnpack_add(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:141:                "qnnpack_add(): Expected both input data types to be ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:283:Tensor xnnp_add(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:376:Tensor qadd(Tensor qa, Tensor qb, double scale, int64_t zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/BinaryOps.cpp:486:static Tensor quantized_add(Tensor qa, Tensor qb, double scale, int64_t zero_point){
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cudnn/BinaryOps.cpp:90:Tensor add(Tensor qa, Tensor qb, double output_scale, int64_t output_zero_point) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gmem_tile.h:260:    inline __device__ void atomic_add(const uint4 (&src)[STGS_PER_LOOP], int mi) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:542:static inline __device__ uint16_t hadd(uint16_t a, uint16_t b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:555:static inline __device__ uint32_t hadd(uint32_t a, uint32_t b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:570:static inline __device__ uint2 hadd(uint2 a, uint2 b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:649:static inline __device__ uint4 hadd(uint4 a, uint4 b) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gemm.h:128:    inline __device__ void add(const Fragment &other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/gemm.h:175:    inline __device__ void add(const Other_fragment_ &other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1161:Tensor add(const Tensor& self, const Scalar& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/benchmarks/tensor_add.cpp:5:static void tensor_add(benchmark::State& state) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:18:  _(+, x.add(y), y.add(x))                                                  \
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2086:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2087:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2109:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2110:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2134:                                    .add(c10::DispatchKey::Tracer)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/op_registration/op_registration_test.cpp:2135:                                    .add(c10::DispatchKey::AutogradCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/core/boxing/impl/kernel_stackbased_test.cpp:193:                                    .add(c10::DispatchKey::TESTING_ONLY_GenericWrapper)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/cuda_atomic_ops_test.cu:48:void test_atomic_add() {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:570:    TestSeed add(uint64_t index) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:1119:    not_inline float add(float a, float b)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:1123:    not_inline double add(double a, double b)
  - add_sparse(SparseCPU, SparseCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:416:Tensor add_sparse(const Tensor& self, const Tensor& other, const Scalar& alpha) {
  - add_sparse_csr(SparseCsrCPU, SparseCsrCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:781:Tensor add_sparse_csr(
  - mkldnn_add(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:28:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/BinaryOps.cpp:101:Tensor mkldnn_add(const Tensor& self, const Tensor& other, const Scalar& alpha) {
  - add_zerotensor(ZeroTensor)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1076:Tensor add_zerotensor(const Tensor& self, const Tensor& other, const Scalar& alpha) {
  - NestedTensor_add_Tensor(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:171:Tensor NestedTensor_add_Tensor(


 - addmm
  - addmm
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Mm.cpp:340:Tensor addmm(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:1362:Tensor _sparse_addmm(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:1620:Tensor sspaddmm(const Tensor& self, const Tensor& mat1, const Tensor& mat2,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorTransformerFunctions.h:33:Tensor NestedTensor_times_Tensor_plus_Tensor_addmm(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorTransformerFunctions.cpp:90:Tensor NestedTensor_times_Tensor_plus_Tensor_addmm(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorTransformerFunctions.cpp:108:      ? at::addmm(
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.h:193:TORCH_API std::vector<Dimname> propagate_names_for_addmm(
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.cpp:356:std::vector<Dimname> propagate_names_for_addmm(
  - addmm_sparse_dense_cpu(SparseCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:1327:static Tensor s_addmm_sparse_dense_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:1339:Tensor addmm_sparse_dense_cpu(
  - addmm_sparse_dense_cuda(SparseCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/SparseCUDATensorMath.cu:141:Tensor s_addmm_sparse_dense_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/SparseCUDATensorMath.cu:153:Tensor addmm_sparse_dense_cuda(
  - addmm_sparse_compressed_dense(SparseCsrCPU, SparseCsrCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:723:Tensor addmm_sparse_compressed_dense(


 - alias
  - alias
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Shape.cpp:49:Tensor _reshape_alias(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.h:12:bool to_will_alias(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1671:Tensor _reshape_alias(const Tensor& self, IntArrayRef sizes, IntArrayRef strides) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:3653:Tensor alias(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:361:bool to_will_alias(
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.cpp:147:bool FunctionSchema::may_alias(const SchemaArgument& lhs, const SchemaArgument& rhs) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.cpp:177:bool FunctionSchema::may_contain_alias(const SchemaArgument& lhs, const SchemaArgument& rhs, bool bidirectional) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.h:408:  bool may_alias(const SchemaArgument& lhs, const SchemaArgument& rhs) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/FunctionalInverses.cpp:161:    // _reshape_alias() isn't available from user code, and is an implementation detail of reshape().
  - alias(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Shape.cpp:49:Tensor _reshape_alias(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.h:12:bool to_will_alias(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1671:Tensor _reshape_alias(const Tensor& self, IntArrayRef sizes, IntArrayRef strides) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:3653:Tensor alias(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:361:bool to_will_alias(
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.cpp:147:bool FunctionSchema::may_alias(const SchemaArgument& lhs, const SchemaArgument& rhs) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.cpp:177:bool FunctionSchema::may_contain_alias(const SchemaArgument& lhs, const SchemaArgument& rhs, bool bidirectional) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.h:408:  bool may_alias(const SchemaArgument& lhs, const SchemaArgument& rhs) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/FunctionalInverses.cpp:161:    // _reshape_alias() isn't available from user code, and is an implementation detail of reshape().


 - amax
  - amax
   - /home/haozhe/code/pytorch/aten/src/ATen/test/reduce_ops_test.cpp:16:        a.amax(c10::IntArrayRef{0, 1}).item<double>(),


 - amin
  - amin
   - /home/haozhe/code/pytorch/aten/src/ATen/test/reduce_ops_test.cpp:20:        a.amin(c10::IntArrayRef{0, 1}).item<double>(),


 - arange.start_step
  - arange
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:119:  static Vectorized<ComplexDbl> arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:165:  static Vectorized<ComplexFlt> arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:291:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:299:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:308:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:590:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:598:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:607:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SobolEngineOps.cpp:180:      at::native::arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:65:bool solve_arange(const Tensor& input, int64_t& start, int64_t& end, int64_t& step) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:920:      // arange(start, stop, step)`. If the solution exists then the
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1004:              (col_indices[dim_indices].mul(blocksize[other_dim]).unsqueeze(1) + arange(blocksize[other_dim]).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1009:              -> (col_indices[[0, 1]].mul(3).unsqueeze(1) + arange(3).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1043:              (row_indices[dim_indices].mul(blocksize[other_dim]).unsqueeze(1) + arange(blocksize[other_dim]).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1053:              (row_indices[dim_indices].mul(blocksize[other_dim]).unsqueeze(1) + arange(blocksize[other_dim]).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1054:              -> (row_indices[[1 3]].mul(2).unsqueeze(1) + arange(2).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:134:Tensor arange(const Scalar& end,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:142:Tensor arange(const Scalar& start, const Scalar& end,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:151:Tensor arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:186:Tensor _dim_arange(const Tensor& like, int64_t dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:1359:      native::arange(window_length, dtype, layout, device, pin_memory)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:3582:        "or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor."
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:154:    // This is equivalent to arange(n_batch) * nnz_per_batch with the same
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:666:            + nnz_per_batch * at::arange(0, n_batch, options).repeat_interleave(ncompressed),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:879:      at::native::arange(not_zero_mask.size(-1), index_dtype, kStrided, index_device)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:884:      at::native::arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1250:  // Equivalent to (arange(batch_numel_nonzero).mul_(nnz)).reshape(batch_sizes_nonempty).
  - arange(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:119:  static Vectorized<ComplexDbl> arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:165:  static Vectorized<ComplexFlt> arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:291:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:299:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:308:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:590:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:598:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:607:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SobolEngineOps.cpp:180:      at::native::arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:65:bool solve_arange(const Tensor& input, int64_t& start, int64_t& end, int64_t& step) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:920:      // arange(start, stop, step)`. If the solution exists then the
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1004:              (col_indices[dim_indices].mul(blocksize[other_dim]).unsqueeze(1) + arange(blocksize[other_dim]).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1009:              -> (col_indices[[0, 1]].mul(3).unsqueeze(1) + arange(3).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1043:              (row_indices[dim_indices].mul(blocksize[other_dim]).unsqueeze(1) + arange(blocksize[other_dim]).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1053:              (row_indices[dim_indices].mul(blocksize[other_dim]).unsqueeze(1) + arange(blocksize[other_dim]).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:1054:              -> (row_indices[[1 3]].mul(2).unsqueeze(1) + arange(2).unsqueeze(0)).flatten(0, 1)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:134:Tensor arange(const Scalar& end,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:142:Tensor arange(const Scalar& start, const Scalar& end,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:151:Tensor arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:186:Tensor _dim_arange(const Tensor& like, int64_t dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:1359:      native::arange(window_length, dtype, layout, device, pin_memory)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:3582:        "or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor."
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:154:    // This is equivalent to arange(n_batch) * nnz_per_batch with the same
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:666:            + nnz_per_batch * at::arange(0, n_batch, options).repeat_interleave(ncompressed),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:879:      at::native::arange(not_zero_mask.size(-1), index_dtype, kStrided, index_device)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:884:      at::native::arange(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1250:  // Equivalent to (arange(batch_numel_nonzero).mul_(nnz)).reshape(batch_sizes_nonempty).


 - argmax
  - argmax
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorCompare.cpp:773:static Tensor argmax(const Tensor& /*self*/, Dimname /*dim*/, bool /*keepdim*/) {


 - argmin
  - argmin
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorCompare.cpp:776:static Tensor argmin(const Tensor& /*self*/, Dimname /*dim*/, bool /*keepdim*/) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:212:static void check_argmax_argmin(


 - as_strided
  - as_strided
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:389:      "Tensor.as_strided(size, stride, ...): size and stride must have the ",
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:393:  // 1. as_strided(sizes, strides, storage_offset + tensor[i].offset() - tensor.offset())
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:410:  // xs.as_strided(physical_sizes, physical_strides, offset) always succeeds
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ConvolutionMM2d.cpp:215:        ? weight.as_strided({s1, s2}, {s2, 1}) // CL: view as {oc, kh*kw*ic}
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1648:      at::as_strided(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1661:    at::as_strided(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorMatmul.cpp:76:               self_buffer.as_strided(self_sizes[i], self_strides[i], self_offsets_ptr[i]),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/cuda/NestedTensorMatmul.cu:408:        self_buffer.as_strided(self_sizes[i], self_strides[i], self_offsets_ptr[i]),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/cuda/NestedTensorMatmul.cu:409:        mat2_buffer.as_strided(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:183:        src.as_strided(index_sizes, src_strides)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:241:        src.as_strided(index_sizes, src_strides)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ScatterGatherKernel.cu:300:        src.as_strided(index_sizes, src_strides)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/LossCTC.cu:663:                                 + log_beta.as_strided({batch_size, log_beta.size(1), max_target_length+1},
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:626:      "Tensor.as_strided(size, stride, ...): size and stride must have the ",
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:632:  // 2. as_strided(sizes, strides, storage_offset + tensor[i].offset() - tensor.offset())
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:650:  // xs.as_strided(physical_sizes, physical_strides, offset) always succeeds
  - as_strided_tensorimpl(ZeroTensor, CPU, CUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1140:Tensor as_strided_tensorimpl(const Tensor& self, IntArrayRef size, IntArrayRef stride, optional<int64_t> storage_offset_) {
  - as_strided_tensorimpl_meta_symint(Meta)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1167:Tensor as_strided_tensorimpl_meta_symint(const Tensor& self, SymIntArrayRef sym_size, SymIntArrayRef sym_stride, optional<c10::SymInt> sym_storage_offset_) {
  - as_strided_tensorimpl_mps(MPS)
  - as_strided_qtensorimpl(QuantizedCPU, QuantizedCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1181:Tensor as_strided_qtensorimpl(const Tensor& self, IntArrayRef size, IntArrayRef stride, optional<int64_t> storage_offset_) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1198:static Tensor as_strided_qtensorimpl(const Tensor& self, IntArrayRef size, IntArrayRef stride, optional<int64_t> storage_offset_,


 - asin
  - asin
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:291:  Vectorized<ComplexDbl> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:292:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:509:  Vectorized<ComplexFlt> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:510:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:222:  Vectorized<double> C10_ALWAYS_INLINE asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:261:  Vectorized<float> C10_ALWAYS_INLINE asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:343:  Vectorized<float> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:225:  Vectorized<c10::complex<float>> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:226:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:310:  Vectorized<T> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1042:  Vectorized<T> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2294:  Vectorized<T> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2295:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:140:  Vectorized<double> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:146:  Vectorized<float> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:190:  Vectorized<c10::complex<double>> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:191:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:364:  Vectorized<T> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:393:  Vectorized<T> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:251:  Vectorized<c10::complex<double>> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:252:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:757:  Vectorized<c10::complex<float>> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:758:    // asin(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:175:  Vectorized<float> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:160:  Vectorized<double> asin() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:1061:asin(const complex<_Tp>& __x)
  - asin_sparse(SparseCPU, SparseCUDA)
  - asin_sparse_csr(SparseCsrCPU, SparseCsrCUDA)


 - asinh
  - asinh
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:909:asinh(const complex<_Tp>& __x)
  - asinh_sparse(SparseCPU, SparseCUDA)
  - asinh_sparse_csr(SparseCsrCPU, SparseCsrCUDA)


 - atan
  - atan
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:314:  Vectorized<ComplexDbl> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:444:  Vectorized<ComplexFlt> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:225:  Vectorized<double> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:264:  Vectorized<float> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:349:  Vectorized<float> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:249:  Vectorized<c10::complex<float>> atan() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:435:inline Vectorized<c10::complex<float>> Vectorized<c10::complex<float>>::atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:313:  Vectorized<T> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1045:  Vectorized<T> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2284:  Vectorized<T> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:143:  Vectorized<double> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:149:  Vectorized<float> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:216:  Vectorized<c10::complex<double>> atan() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:400:inline Vectorized<c10::complex<double>> Vectorized<c10::complex<double>>::atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:367:  Vectorized<T> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:396:  Vectorized<T> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:277:  Vectorized<c10::complex<double>> atan() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:469:inline Vectorized<c10::complex<double>> Vectorized<c10::complex<double>>::atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:780:  Vectorized<c10::complex<float>> atan() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:973:inline Vectorized<c10::complex<float>> Vectorized<c10::complex<float>>::atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:178:  Vectorized<float> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:163:  Vectorized<double> atan() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:1108:atan(const complex<_Tp>& __x)
  - atan_sparse(SparseCPU, SparseCUDA)
  - atan_sparse_csr(SparseCsrCPU, SparseCsrCUDA)


 - atanh
  - atanh
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:972:atanh(const complex<_Tp>& __x)
  - atanh_sparse(SparseCPU, SparseCUDA)
  - atanh_sparse_csr(SparseCsrCPU, SparseCsrCUDA)


 - avg_pool2d
  - avg_pool2d
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Pool.cpp:13:Tensor adaptive_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Pool.cpp:222:Tensor avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:52:Tensor mkldnn_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:96:Tensor mkldnn_adaptive_avg_pool2d(Tensor const& input, IntArrayRef output_size) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:414:Tensor mkldnn_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:487:Tensor mkldnn_adaptive_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/AdaptiveAveragePooling.cpp:36:        "adaptive_avg_pool2d(): Expected input to have non-zero size for non-batch dimensions, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AdaptiveAveragePooling.cu:455:        "adaptive_avg_pool2d(): Expected input to have non-zero size for non-batch dimensions, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AdaptiveAveragePooling.cu:465:                    "adaptive_avg_pool2d(): Expected 4D tensor, but got ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AveragePool2d.cpp:182:Tensor q_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AveragePool2d.cpp:263:Tensor qnnpack_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AveragePool2d.cpp:279:      "qnnpack_avg_pool2d(): Expected input to be 4-dimensional: got ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AveragePool2d.cpp:282:                "qnnpack_avg_pool2d(): Expected input data type ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/QnnpackUtils.h:434:Tensor qnnpack_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AdaptiveAveragePooling.cpp:254:Tensor q_adaptive_avg_pool2d(const Tensor& input, IntArrayRef output_size) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AdaptiveAveragePooling.cpp:266:Tensor qnnpack_adaptive_avg_pool2d(
  - mkldnn_avg_pool2d(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:52:Tensor mkldnn_avg_pool2d(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:414:Tensor mkldnn_avg_pool2d(
  - avg_pool2d_quantized_cpu(QuantizedCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AveragePool2d.cpp:363:Tensor avg_pool2d_quantized_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/AdaptiveAveragePooling.cpp:314:Tensor adaptive_avg_pool2d_quantized_cpu(


 - avg_pool2d_backward
  - avg_pool2d_backward
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:148:Tensor mkldnn_avg_pool2d_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:184:Tensor mkldnn_adaptive_avg_pool2d_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:574:Tensor mkldnn_avg_pool2d_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:642:Tensor mkldnn_adaptive_avg_pool2d_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/AdaptiveAveragePooling.cpp:70:        "adaptive_avg_pool2d_backward(): Expected grad_output to have non-zero size for non-batch dimensions, "
  - mkldnn_avg_pool2d_backward(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:148:Tensor mkldnn_avg_pool2d_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Pooling.cpp:574:Tensor mkldnn_avg_pool2d_backward(


 - bitwise_and.Tensor
  - bitwise_and
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1196:Tensor bitwise_and(const Tensor& self, const Scalar& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1200:Tensor bitwise_and(const Scalar& self, const Tensor& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:29:  _(&, x.bitwise_and(y), y.bitwise_and(x))                                  \


 - bitwise_not
  - bitwise_not



 - bitwise_or.Tensor
  - bitwise_or
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1229:Tensor bitwise_or(const Tensor& self, const Scalar& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1233:Tensor bitwise_or(const Scalar& self, const Tensor& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:30:  _(|, x.bitwise_or(y), y.bitwise_or(x))                                    \


 - bitwise_xor.Tensor
  - bitwise_xor
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1262:Tensor bitwise_xor(const Tensor& self, const Scalar& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1266:Tensor bitwise_xor(const Scalar& self, const Tensor& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:31:  _(^, x.bitwise_xor(y), y.bitwise_xor(x))                                  \


 - bmm
  - bmm
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesLinearAlgebra.cpp:103:      "Shape mismatch: Got incorrect dims for bmm(a, b). "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Linear.cpp:172:  // then the permuted output is a view of bmm(left, right)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1518:Tensor addbmm(const Tensor& self, const Tensor& batch1, const Tensor& batch2, const Scalar& beta, const Scalar& alpha) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:1848:  // t2 will be expanded to a tensor of shape [b, n, k] and then we do t1.bmm(t2_expanded)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/native_test.cpp:162:          .bmm(d1.view({1, 3, 1}).expand({24, 3, 1}))
   - /home/haozhe/code/pytorch/aten/src/ATen/test/native_test.cpp:182:                        .bmm(d2Acc.expand({24, 3, 4}))
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:894:      "bmm(self, other): Shape mismatch: expected 3D `self` "
  - bmm_sparse_cpu(SparseCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:1899:Tensor bmm_sparse_cpu(const SparseTensor& self, const Tensor& mat2) {
  - bmm_sparse_cuda(SparseCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/SparseCUDATensorMath.cu:672:Tensor bmm_sparse_cuda(const SparseTensor& self, const Tensor& mat2) {
  - bmm_nested(NestedTensorCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorMatmul.cpp:22:Tensor bmm_nested(const Tensor& self, const Tensor& mat2) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorMatmul.cpp:82:static Tensor matmul_with_bmm_nested(const Tensor& self, const Tensor& mat2) {
  - bmm_nested_cuda(NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/cuda/NestedTensorMatmul.cu:285:Tensor bmm_nested_cuda(const Tensor& self, const Tensor& mat2) {


 - cat
  - cat
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:544:  // Then, we'll do at::cat(tensors_to_cat, ...).
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Concat.cpp:270:Tensor cat(const at::ITensorListRef& tensors, const int64_t in_dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:284:        "torch.cat(): input types can't be cast to the desired output type ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:632:Tensor cat(TensorList tensors, Dimname dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:642:Tensor concat(TensorList tensors, Dimname dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:650:Tensor concat(TensorList tensors, int64_t dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:722:    // then torch.cat((t1,t1,t1),1) should have indices
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:809:        at::cat(idxs_pieces, 1),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:810:        at::cat(vals_pieces),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/RNN.cpp:640:tpair_of<Tensor> hidden_concat(at::ArrayRef<tpair_of<Tensor>> hiddens) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/RNN.cpp:975:            hidden_concat(hiddens)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/RNN.cpp:1053:        at::cat({fw_result.outputs.data, rev_result.outputs.data}, -1),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/RNN.cpp:1126:std::tuple<io_type, Tensor> _rnn_impl_with_concat(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:665:    at::cat({compressed_indices.slice(1, 0, ncompressed).flatten()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Shape.cu:238:void parallel_cat(const Tensor &out, const MaterializedITensorListRef& inputs, int64_t dimension,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:126:Tensor qcat(
   - /home/haozhe/code/pytorch/aten/src/ATen/FunctionalTensorWrapper.cpp:443:    // Example of when that can happen: torch.cat(function_input_tensor, global_state_tensor).
  - cat_sparse(SparseCPU, SparseCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:819:Tensor cat_sparse(const ITensorListRef& tensors, int64_t dim) {
  - cat_quantized_cpu(QuantizedCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/TensorShape.cpp:160:Tensor cat_quantized_cpu(const ITensorListRef& qxs, int64_t dim) {


 - clamp
  - clamp
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vsx_helpers.h:198:  Vectorized<operand_type> C10_ALWAYS_INLINE clamp(                             \
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:730:Vectorized<float> inline clamp(const Vectorized<float>& a, const Vectorized<float>& min, const Vectorized<float>& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1025:Vectorized<int64_t> inline clamp(const Vectorized<int64_t>& a, const Vectorized<int64_t>& min_val, const Vectorized<int64_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1030:Vectorized<int32_t> inline clamp(const Vectorized<int32_t>& a, const Vectorized<int32_t>& min_val, const Vectorized<int32_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1035:Vectorized<int16_t> inline clamp(const Vectorized<int16_t>& a, const Vectorized<int16_t>& min_val, const Vectorized<int16_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1040:Vectorized<int8_t> inline clamp(const Vectorized<int8_t>& a, const Vectorized<int8_t>& min_val, const Vectorized<int8_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1045:Vectorized<uint8_t> inline clamp(const Vectorized<uint8_t>& a, const Vectorized<uint8_t>& min_val, const Vectorized<uint8_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:688:Vectorized<BFloat16> inline clamp(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:886:Vectorized<Half> inline clamp(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_qint.h:61:__m256i pack_saturate_and_clamp(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1353:  Vectorized<typex> C10_ALWAYS_INLINE clamp(                      \
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:347:Vectorized<double> inline clamp(const Vectorized<double>& a, const Vectorized<double>& min, const Vectorized<double>& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:382:Vectorized<float> inline clamp(const Vectorized<float>& a, const Vectorized<float>& min, const Vectorized<float>& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:688:Vectorized<T> inline clamp(const Vectorized<T> &a, const Vectorized<T> &min_vec, const Vectorized<T> &max_vec) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1065:Vectorized<int64_t> inline clamp(const Vectorized<int64_t>& a, const Vectorized<int64_t>& min_val, const Vectorized<int64_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1070:Vectorized<int32_t> inline clamp(const Vectorized<int32_t>& a, const Vectorized<int32_t>& min_val, const Vectorized<int32_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1075:Vectorized<int16_t> inline clamp(const Vectorized<int16_t>& a, const Vectorized<int16_t>& min_val, const Vectorized<int16_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1080:Vectorized<int8_t> inline clamp(const Vectorized<int8_t>& a, const Vectorized<int8_t>& min_val, const Vectorized<int8_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1085:Vectorized<uint8_t> inline clamp(const Vectorized<uint8_t>& a, const Vectorized<uint8_t>& min_val, const Vectorized<uint8_t>& max_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:807:Vectorized<BFloat16> inline clamp(const Vectorized<BFloat16>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:1018:Vectorized<Half> inline clamp(const Vectorized<Half>& a,
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_qint.h:61:__m512i pack_saturate_and_clamp(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:429:Vectorized<float> inline clamp(const Vectorized<float>& a, const Vectorized<float>& min, const Vectorized<float>& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:385:Vectorized<double> inline clamp(const Vectorized<double>& a, const Vectorized<double>& min, const Vectorized<double>& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:372:kernel void clamp(texture2d_array<half, access::read> in_arr[[texture(0), function_constant(clamp_is_arr)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Clamp.cpp:12:Tensor _clamp(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Clamp.cpp:69:Tensor clamp(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qclamp.cpp:34:Tensor qnnpack_clamp(Tensor input, const Scalar& min, const Scalar& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/utils.h:386:static inline __device__ T clamp(T x, T lb, T ub) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:380:T clamp(const T& a, const T& min, const T& max) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:416:void filter_clamp(T& f, T& s, T& t) {
  - clamp_quantized_cpu(QuantizedCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qclamp.cpp:129:Tensor clamp_quantized_cpu(


 - clone
  - clone
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesUnaryOps.cpp:27:      "NYI: Tensor.clone(memory_format) inside vmap is only supported with ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Clone.cpp:17:Tensor clone(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:710:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1410:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1887:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:751:                                                      compressed_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:752:                                                      plain_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:753:                                                      self.values().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:779:        self.crow_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:780:        self.col_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:789:        self.ccol_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:790:        self.row_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:799:        self.crow_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:800:        self.col_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:810:        self.ccol_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:811:        self.row_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:256:      compressed_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:257:      plain_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:338:      compressed_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:339:      plain_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:390:      self.crow_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:391:      self.col_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseUnaryOps.cpp:88:      input.indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:91:      other_impl->get_nested_sizes().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:92:      other_impl->get_nested_strides().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:101:      self_impl->get_nested_sizes().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:102:      self_impl->get_nested_strides().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:447:  // Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat> optional_memory_format)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:483:        self.q_per_channel_scales().clone(at::MemoryFormat::Preserve),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:484:        self.q_per_channel_zero_points().clone(at::MemoryFormat::Preserve),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:1598:Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp:30:Tensor mkldnn_clone(const Tensor& self, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp:69:Tensor mkldnn_clone(const Tensor& self, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/SpectralOps.cpp:383:                         .clone(MemoryFormat::Contiguous)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1563:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SparseTensorUtils.cpp:124:      t._indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/QTensor.cpp:189:Tensor quantized_clone(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/QTensor.cpp:197:  // Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat>
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:41:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:91:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:133:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:169:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebraUtils.h:78:static inline c10::MaybeOwned<Tensor> borrow_else_clone(const bool cond, const Tensor& borrow, const Tensor& clone, const bool contig) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebraUtils.h:80:              : c10::MaybeOwned<Tensor>::owned(contig ? clone.clone(MemoryFormat::Contiguous)
   - /home/haozhe/code/pytorch/aten/src/ATen/CPUGeneratorImpl.h:16:  std::shared_ptr<CPUGeneratorImpl> clone() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/CPUGeneratorImpl.cpp:337:std::shared_ptr<CPUGeneratorImpl> CPUGeneratorImpl::clone() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/Generator.h:135:  Generator clone() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/NamedTensor.h:40:  std::unique_ptr<c10::NamedTensorMetaInterface> clone() const override {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/jit_type.h:833:  TensorTypePtr clone() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:776:      "NYI: Tensor.clone(memory_format) inside vmap is only supported with ",
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/MPSGeneratorImpl.h:32:  std::shared_ptr<MPSGeneratorImpl> clone() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/MemoryOverlap.cpp:37:    "refers to a single memory location. Please clone() the tensor before "
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/CUDAGeneratorImpl.h:96:  std::shared_ptr<CUDAGeneratorImpl> clone() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/CUDAGeneratorImpl.cpp:342:std::shared_ptr<CUDAGeneratorImpl> CUDAGeneratorImpl::clone() const {
  - clone(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesUnaryOps.cpp:27:      "NYI: Tensor.clone(memory_format) inside vmap is only supported with ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Clone.cpp:17:Tensor clone(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:710:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1410:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1887:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:751:                                                      compressed_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:752:                                                      plain_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:753:                                                      self.values().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:779:        self.crow_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:780:        self.col_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:789:        self.ccol_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:790:        self.row_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:799:        self.crow_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:800:        self.col_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:810:        self.ccol_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:811:        self.row_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:256:      compressed_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:257:      plain_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:338:      compressed_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:339:      plain_indices.clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:390:      self.crow_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:391:      self.col_indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseUnaryOps.cpp:88:      input.indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:91:      other_impl->get_nested_sizes().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:92:      other_impl->get_nested_strides().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:101:      self_impl->get_nested_sizes().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:102:      self_impl->get_nested_strides().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:447:  // Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat> optional_memory_format)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:483:        self.q_per_channel_scales().clone(at::MemoryFormat::Preserve),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:484:        self.q_per_channel_zero_points().clone(at::MemoryFormat::Preserve),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:1598:Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp:30:Tensor mkldnn_clone(const Tensor& self, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp:69:Tensor mkldnn_clone(const Tensor& self, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/SpectralOps.cpp:383:                         .clone(MemoryFormat::Contiguous)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1563:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SparseTensorUtils.cpp:124:      t._indices().clone(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/QTensor.cpp:189:Tensor quantized_clone(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/QTensor.cpp:197:  // Tensor clone(const Tensor& src, c10::optional<c10::MemoryFormat>
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:41:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:91:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:133:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorAdvancedIndexing.cpp:169:      "Please clone() the tensor before performing this operation. "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebraUtils.h:78:static inline c10::MaybeOwned<Tensor> borrow_else_clone(const bool cond, const Tensor& borrow, const Tensor& clone, const bool contig) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebraUtils.h:80:              : c10::MaybeOwned<Tensor>::owned(contig ? clone.clone(MemoryFormat::Contiguous)
   - /home/haozhe/code/pytorch/aten/src/ATen/CPUGeneratorImpl.h:16:  std::shared_ptr<CPUGeneratorImpl> clone() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/CPUGeneratorImpl.cpp:337:std::shared_ptr<CPUGeneratorImpl> CPUGeneratorImpl::clone() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/Generator.h:135:  Generator clone() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/NamedTensor.h:40:  std::unique_ptr<c10::NamedTensorMetaInterface> clone() const override {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/jit_type.h:833:  TensorTypePtr clone() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:776:      "NYI: Tensor.clone(memory_format) inside vmap is only supported with ",
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/MPSGeneratorImpl.h:32:  std::shared_ptr<MPSGeneratorImpl> clone() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/MemoryOverlap.cpp:37:    "refers to a single memory location. Please clone() the tensor before "
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/CUDAGeneratorImpl.h:96:  std::shared_ptr<CUDAGeneratorImpl> clone() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/CUDAGeneratorImpl.cpp:342:std::shared_ptr<CUDAGeneratorImpl> CUDAGeneratorImpl::clone() const {
  - clone_sparse(SparseCPU, SparseCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensor.cpp:467:SparseTensor clone_sparse(
  - clone_sparse_compressed(SparseCsrCPU, SparseCsrCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:734:SparseCsrTensor clone_sparse_compressed(
  - mkldnn_clone(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp:30:Tensor mkldnn_clone(const Tensor& self, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorShape.cpp:69:Tensor mkldnn_clone(const Tensor& self, c10::optional<c10::MemoryFormat> optional_memory_format) {
  - quantized_clone(QuantizedCPU, QuantizedCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/QTensor.cpp:189:Tensor quantized_clone(
  - clone_nested(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorFactories.cpp:133:Tensor clone_nested(


 - col2im
  - col2im
   - /home/haozhe/code/pytorch/aten/src/ATen/native/im2col.h:87:static void col2im(
  - col2im_cpu(CPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Col2Im.cpp:204:Tensor col2im_cpu(
  - col2im_cuda(CUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Col2Im.cu:157:Tensor col2im_cuda(


 - constant_pad_nd
  - constant_pad_nd
   - /home/haozhe/code/pytorch/aten/src/ATen/native/PadNd.cpp:29:Tensor constant_pad_nd(const Tensor& self, IntArrayRef pad, const Scalar& value) {
  - constant_pad_nd(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/PadNd.cpp:29:Tensor constant_pad_nd(const Tensor& self, IntArrayRef pad, const Scalar& value) {
  - constant_pad_nd_mps(MPS)


 - convolution
  - convolution
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:33:at::Tensor miopen_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:94:at::Tensor miopen_depthwise_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:794:Tensor miopen_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:895:Tensor miopen_depthwise_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NNPACK.cpp:24:at::Tensor _nnpack_spatial_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NNPACK.cpp:137:Tensor _nnpack_spatial_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Convolution.cpp:766:Tensor convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Convolution.cpp:791:Tensor quantized_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:827:at::Tensor complex_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1162:at::Tensor convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1452:at::Tensor _convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1692:at::Tensor _convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvShared.cpp:213:Tensor cudnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvPlaceholders.cpp:27:at::Tensor cudnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:24:Tensor mkldnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:259:static Tensor _mkldnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:327:Tensor mkldnn_convolution(
  - convolution(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:33:at::Tensor miopen_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:94:at::Tensor miopen_depthwise_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:794:Tensor miopen_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:895:Tensor miopen_depthwise_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NNPACK.cpp:24:at::Tensor _nnpack_spatial_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NNPACK.cpp:137:Tensor _nnpack_spatial_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Convolution.cpp:766:Tensor convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Convolution.cpp:791:Tensor quantized_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:827:at::Tensor complex_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1162:at::Tensor convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1452:at::Tensor _convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1692:at::Tensor _convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvShared.cpp:213:Tensor cudnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvPlaceholders.cpp:27:at::Tensor cudnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:24:Tensor mkldnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:259:static Tensor _mkldnn_convolution(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:327:Tensor mkldnn_convolution(


 - convolution_backward
  - convolution_backward
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:59:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:115:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_depthwise_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:1420:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:1441:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_depthwise_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1977:std::tuple<Tensor, Tensor, Tensor> convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:2070:        at::mps_convolution_backward(input, grad_output, weight, params.padding,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvShared.cpp:373:std::tuple<at::Tensor,at::Tensor> cudnn_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvPlaceholders.cpp:48:std::tuple<at::Tensor,at::Tensor> cudnn_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:42:static std::tuple<Tensor, Tensor, Tensor> mkldnn_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:915:std::tuple<Tensor, Tensor, Tensor> mkldnn_convolution_backward(
  - convolution_backward(CompositeExplicitAutograd, CUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:59:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:115:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_depthwise_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:1420:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:1441:std::tuple<at::Tensor,at::Tensor,at::Tensor> miopen_depthwise_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:1977:std::tuple<Tensor, Tensor, Tensor> convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Convolution.cpp:2070:        at::mps_convolution_backward(input, grad_output, weight, params.padding,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvShared.cpp:373:std::tuple<at::Tensor,at::Tensor> cudnn_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cudnn/ConvPlaceholders.cpp:48:std::tuple<at::Tensor,at::Tensor> cudnn_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:42:static std::tuple<Tensor, Tensor, Tensor> mkldnn_convolution_backward(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/Conv.cpp:915:std::tuple<Tensor, Tensor, Tensor> mkldnn_convolution_backward(


 - cos
  - cos
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:309:  Vectorized<ComplexDbl> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:329:  Vectorized<ComplexDbl> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:383:  Vectorized<ComplexFlt> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:453:  Vectorized<ComplexFlt> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:219:  Vectorized<double> C10_ALWAYS_INLINE acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:288:  Vectorized<double> C10_ALWAYS_INLINE cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:258:  Vectorized<float> C10_ALWAYS_INLINE acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:328:  Vectorized<float> C10_ALWAYS_INLINE cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:337:  Vectorized<float> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:541:  Vectorized<float> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:246:  Vectorized<c10::complex<float>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:285:  Vectorized<c10::complex<float>> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:307:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:468:  Vectorized<T> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1039:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1089:  Vectorized<T> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2319:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2330:  Vectorized<T> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:137:  Vectorized<double> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:220:  Vectorized<double> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:143:  Vectorized<float> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:227:  Vectorized<float> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:210:  Vectorized<c10::complex<double>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:252:  Vectorized<c10::complex<double>> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:361:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:447:  Vectorized<T> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:390:  Vectorized<T> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:551:  Vectorized<T> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:271:  Vectorized<c10::complex<double>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:313:  Vectorized<c10::complex<double>> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:777:  Vectorized<c10::complex<float>> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:816:  Vectorized<c10::complex<float>> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:172:  Vectorized<float> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:256:  Vectorized<float> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:157:  Vectorized<double> acos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:240:  Vectorized<double> cos() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalNeuronType.h:54:API_AVAILABLE(ios(11.3), macos(10.13), macCatalyst(13.0))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNFullyConnectedOp.h:7:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNNeuronOp.h:12:API_AVAILABLE(ios(11.3), macos(10.13), macCatalyst(13.0))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSImageWrapper.h:12:class API_AVAILABLE(ios(11.0), macos(10.13)) MPSImageWrapper {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNUtils.h:34:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNUtils.h:39:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNUtils.h:47:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNConvOp.h:6:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/mpscnn/MPSCNNConvOp.h:18:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalContext.h:6:API_AVAILABLE(ios(11.0), macos(10.13))
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:1071:acos(const complex<_Tp>& __x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:1129:cos(const complex<_Tp>& __x)


 - cosh
  - cosh
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:332:  Vectorized<ComplexDbl> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:386:  Vectorized<ComplexFlt> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:291:  Vectorized<double> C10_ALWAYS_INLINE cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:331:  Vectorized<float> C10_ALWAYS_INLINE cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:547:  Vectorized<float> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:288:  Vectorized<c10::complex<float>> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:471:  Vectorized<T> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1096:  Vectorized<T> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2333:  Vectorized<T> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:223:  Vectorized<double> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:230:  Vectorized<float> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:255:  Vectorized<c10::complex<double>> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:450:  Vectorized<T> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:554:  Vectorized<T> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:316:  Vectorized<c10::complex<double>> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:819:  Vectorized<c10::complex<float>> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:259:  Vectorized<float> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:243:  Vectorized<double> cosh() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:938:acosh(const complex<_Tp>& __x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:1020:cosh(const complex<_Tp>& __x)


 - div.Scalar
  - div
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:328:        vec_div(vd_one, _vec0), // vec_re(_vec0) is estimated one.
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:329:        vec_div(vd_one, _vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:132:kernel void elementwise_div(texture2d_array<half, access::read> in0[[texture(0)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/QuantizedFunctions.h:40:Tensor quantized_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp:273:      TORCH_SELECTIVE_SCHEMA("vulkan_quantized::div(Tensor qa, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Arithmetic.cpp:460:Tensor quantized_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Loss.cpp:239:Tensor kl_div(const Tensor& input, const Tensor& target, int64_t reduction, bool log_target) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleLinear1d.cu:153:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleLinear1d.cu:197:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleTrilinear3d.cu:283:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleTrilinear3d.cu:353:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:611:            dim3 grid_size(at::ceil_div(output_plane_size, static_cast<int64_t>(256)), \
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:664:            dim3 grid_size(at::ceil_div(output_plane_size, static_cast<int64_t>(256)), \
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:321:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:349:          <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:418:          <<<ceil_div(num_kernels, static_cast<size_t>(num_threads)), num_threads, 0, stream>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:448:          <<<ceil_div(num_kernels, static_cast<size_t>(num_threads)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:564:  __device__ inline unsigned int div(unsigned int n) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest1d.cu:127:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest1d.cu:175:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:41:int64_t ceil_div(int64_t x, int64_t y) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:260:      krn_partials_per_segment<<<ceil_div(max_segments, 32), 32, 0, stream>>> (
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:293:      krn_partial_segment_offset<<<ceil_div(max_segments, 32), 32, 0, stream>>> (
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:255:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:387:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:410:    dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool2d.cu:403:              <<<ceil_div(count, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest3d.cu:182:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest3d.cu:255:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBicubic2d.cu:208:            <<<ceil_div(num_output_elements, max_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBicubic2d.cu:263:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:502:      dim3 grid(ceil_div(num_indices, (int64_t) indices_per_block),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:503:           std::min<int>(at::cuda::getCurrentDeviceProperties()->maxGridSize[1], ceil_div(sliceSize, (int64_t) (warp_size*UNROLL))),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:632:      dim3 grid(ceil_div(num_indices, (int64_t) indices_per_block),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:633:           std::min<int>(at::cuda::getCurrentDeviceProperties()->maxGridSize[1], ceil_div(sliceSize, (int64_t) (warp_size*UNROLL))),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:410:        dim3 grid(ceil_div(owidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:411:                  ceil_div(oheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:540:          dim3 grid(ceil_div(iwidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:541:                    ceil_div(iheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:569:          dim3 grid(ceil_div(owidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:570:                    ceil_div(oheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:159:    dim3 grid(ceil_div(owidth, static_cast<int>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:160:              ceil_div(oheight, static_cast<int>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:262:    dim3 grid(ceil_div(owidth, static_cast<int>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:263:              ceil_div(oheight, static_cast<int>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/attention.cu:978:         compute_logsumexp ? ceil_div(max_seqlen_q, kAlignLSE) * kAlignLSE : 0},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/gemm_kernel_utils.h:87:constexpr CUTLASS_HOST_DEVICE integer ceil_div(integer n, integer m) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:336:          ceil_div(num_queries, (int32_t)kQueriesPerBlock),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:950:          : ceil_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_backward.h:2501:          ceil_div(p.head_dim_value, kElementsPerAccess * kNumThreadsPerLine) *
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/gemm/mma_from_smem.h:1604:        {(int32_t)0, (int32_t)ceil_div(lse_extents, kAlignLSE) * kAlignLSE},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:889:Tensor div(const Tensor& self, const Scalar& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:901:Tensor div(const Tensor& self, const Scalar& other, c10::optional<c10::string_view> rounding_mode) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:24:    x.div(y),                                                               \
   - /home/haozhe/code/pytorch/aten/src/ATen/ceil_div.h:11:C10_ALWAYS_INLINE C10_HOST_DEVICE T ceil_div(T a, T b) {
  - div(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:328:        vec_div(vd_one, _vec0), // vec_re(_vec0) is estimated one.
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:329:        vec_div(vd_one, _vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:132:kernel void elementwise_div(texture2d_array<half, access::read> in0[[texture(0)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/QuantizedFunctions.h:40:Tensor quantized_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp:273:      TORCH_SELECTIVE_SCHEMA("vulkan_quantized::div(Tensor qa, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Arithmetic.cpp:460:Tensor quantized_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Loss.cpp:239:Tensor kl_div(const Tensor& input, const Tensor& target, int64_t reduction, bool log_target) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleLinear1d.cu:153:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleLinear1d.cu:197:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleTrilinear3d.cu:283:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleTrilinear3d.cu:353:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:611:            dim3 grid_size(at::ceil_div(output_plane_size, static_cast<int64_t>(256)), \
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:664:            dim3 grid_size(at::ceil_div(output_plane_size, static_cast<int64_t>(256)), \
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:321:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:349:          <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:418:          <<<ceil_div(num_kernels, static_cast<size_t>(num_threads)), num_threads, 0, stream>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:448:          <<<ceil_div(num_kernels, static_cast<size_t>(num_threads)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:564:  __device__ inline unsigned int div(unsigned int n) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest1d.cu:127:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest1d.cu:175:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:41:int64_t ceil_div(int64_t x, int64_t y) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:260:      krn_partials_per_segment<<<ceil_div(max_segments, 32), 32, 0, stream>>> (
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:293:      krn_partial_segment_offset<<<ceil_div(max_segments, 32), 32, 0, stream>>> (
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:255:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:387:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:410:    dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool2d.cu:403:              <<<ceil_div(count, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest3d.cu:182:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest3d.cu:255:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBicubic2d.cu:208:            <<<ceil_div(num_output_elements, max_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBicubic2d.cu:263:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:502:      dim3 grid(ceil_div(num_indices, (int64_t) indices_per_block),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:503:           std::min<int>(at::cuda::getCurrentDeviceProperties()->maxGridSize[1], ceil_div(sliceSize, (int64_t) (warp_size*UNROLL))),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:632:      dim3 grid(ceil_div(num_indices, (int64_t) indices_per_block),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:633:           std::min<int>(at::cuda::getCurrentDeviceProperties()->maxGridSize[1], ceil_div(sliceSize, (int64_t) (warp_size*UNROLL))),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:410:        dim3 grid(ceil_div(owidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:411:                  ceil_div(oheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:540:          dim3 grid(ceil_div(iwidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:541:                    ceil_div(iheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:569:          dim3 grid(ceil_div(owidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:570:                    ceil_div(oheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:159:    dim3 grid(ceil_div(owidth, static_cast<int>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:160:              ceil_div(oheight, static_cast<int>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:262:    dim3 grid(ceil_div(owidth, static_cast<int>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:263:              ceil_div(oheight, static_cast<int>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/attention.cu:978:         compute_logsumexp ? ceil_div(max_seqlen_q, kAlignLSE) * kAlignLSE : 0},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/gemm_kernel_utils.h:87:constexpr CUTLASS_HOST_DEVICE integer ceil_div(integer n, integer m) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:336:          ceil_div(num_queries, (int32_t)kQueriesPerBlock),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:950:          : ceil_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_backward.h:2501:          ceil_div(p.head_dim_value, kElementsPerAccess * kNumThreadsPerLine) *
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/gemm/mma_from_smem.h:1604:        {(int32_t)0, (int32_t)ceil_div(lse_extents, kAlignLSE) * kAlignLSE},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:889:Tensor div(const Tensor& self, const Scalar& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:901:Tensor div(const Tensor& self, const Scalar& other, c10::optional<c10::string_view> rounding_mode) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:24:    x.div(y),                                                               \
   - /home/haozhe/code/pytorch/aten/src/ATen/ceil_div.h:11:C10_ALWAYS_INLINE C10_HOST_DEVICE T ceil_div(T a, T b) {
  - NestedTensor_div_Scalar(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:211:Tensor NestedTensor_div_Scalar(const Tensor& self, const Scalar& other) {


 - div.Tensor
  - div
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:328:        vec_div(vd_one, _vec0), // vec_re(_vec0) is estimated one.
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:329:        vec_div(vd_one, _vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/metal/MetalShaders.h:132:kernel void elementwise_div(texture2d_array<half, access::read> in0[[texture(0)]],
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/QuantizedFunctions.h:40:Tensor quantized_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Register.cpp:273:      TORCH_SELECTIVE_SCHEMA("vulkan_quantized::div(Tensor qa, "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Arithmetic.cpp:460:Tensor quantized_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Loss.cpp:239:Tensor kl_div(const Tensor& input, const Tensor& target, int64_t reduction, bool log_target) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleLinear1d.cu:153:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleLinear1d.cu:197:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleTrilinear3d.cu:283:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleTrilinear3d.cu:353:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:611:            dim3 grid_size(at::ceil_div(output_plane_size, static_cast<int64_t>(256)), \
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ReflectionPad.cu:664:            dim3 grid_size(at::ceil_div(output_plane_size, static_cast<int64_t>(256)), \
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:321:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:349:          <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:418:          <<<ceil_div(num_kernels, static_cast<size_t>(num_threads)), num_threads, 0, stream>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBilinear2d.cu:448:          <<<ceil_div(num_kernels, static_cast<size_t>(num_threads)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:564:  __device__ inline unsigned int div(unsigned int n) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest1d.cu:127:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest1d.cu:175:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:41:int64_t ceil_div(int64_t x, int64_t y) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:260:      krn_partials_per_segment<<<ceil_div(max_segments, 32), 32, 0, stream>>> (
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/EmbeddingBackwardKernel.cu:293:      krn_partial_segment_offset<<<ceil_div(max_segments, 32), 32, 0, stream>>> (
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:255:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:387:        <<<ceil_div(num_kernels, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest2d.cu:410:    dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool2d.cu:403:              <<<ceil_div(count, num_threads), num_threads, 0, at::cuda::getCurrentCUDAStream()>>>(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest3d.cu:182:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleNearest3d.cu:255:  dim3 gdim{ceil_div(n, bdim.x)};
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBicubic2d.cu:208:            <<<ceil_div(num_output_elements, max_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/UpSampleBicubic2d.cu:263:            <<<ceil_div(num_kernels, num_threads),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:502:      dim3 grid(ceil_div(num_indices, (int64_t) indices_per_block),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:503:           std::min<int>(at::cuda::getCurrentDeviceProperties()->maxGridSize[1], ceil_div(sliceSize, (int64_t) (warp_size*UNROLL))),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:632:      dim3 grid(ceil_div(num_indices, (int64_t) indices_per_block),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:633:           std::min<int>(at::cuda::getCurrentDeviceProperties()->maxGridSize[1], ceil_div(sliceSize, (int64_t) (warp_size*UNROLL))),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:410:        dim3 grid(ceil_div(owidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:411:                  ceil_div(oheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:540:          dim3 grid(ceil_div(iwidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:541:                    ceil_div(iheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:569:          dim3 grid(ceil_div(owidth, static_cast<int64_t>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/AveragePool3d.cu:570:                    ceil_div(oheight, static_cast<int64_t>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:159:    dim3 grid(ceil_div(owidth, static_cast<int>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:160:              ceil_div(oheight, static_cast<int>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:262:    dim3 grid(ceil_div(owidth, static_cast<int>(block.x)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/DilatedMaxPool3d.cu:263:              ceil_div(oheight, static_cast<int>(block.y)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/attention.cu:978:         compute_logsumexp ? ceil_div(max_seqlen_q, kAlignLSE) * kAlignLSE : 0},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/gemm_kernel_utils.h:87:constexpr CUTLASS_HOST_DEVICE integer ceil_div(integer n, integer m) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:336:          ceil_div(num_queries, (int32_t)kQueriesPerBlock),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:950:          : ceil_div(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_backward.h:2501:          ceil_div(p.head_dim_value, kElementsPerAccess * kNumThreadsPerLine) *
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/gemm/mma_from_smem.h:1604:        {(int32_t)0, (int32_t)ceil_div(lse_extents, kAlignLSE) * kAlignLSE},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:889:Tensor div(const Tensor& self, const Scalar& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:901:Tensor div(const Tensor& self, const Scalar& other, c10::optional<c10::string_view> rounding_mode) {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorOperators.h:24:    x.div(y),                                                               \
   - /home/haozhe/code/pytorch/aten/src/ATen/ceil_div.h:11:C10_ALWAYS_INLINE C10_HOST_DEVICE T ceil_div(T a, T b) {
  - div_sparse(SparseCPU, SparseCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:257:Tensor div_sparse(const Tensor& self, const Tensor& value) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp:274:Tensor div_sparse(const Tensor& self, const Tensor& value, c10::optional<c10::string_view> rounding_mode) {
  - div_zerotensor(ZeroTensor)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1023:Tensor div_zerotensor(const Tensor& self, const Tensor& other) {
  - NestedTensor_div_Tensor(NestedTensorCPU, NestedTensorCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:203:Tensor NestedTensor_div_Tensor(const Tensor& self, const Tensor& other) {


 - embedding_dense_backward
  - embedding_dense_backward
 - empty.memory_format
  - empty
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesHelper.cpp:37:optional<int64_t> valIfNonempty(optional<int64_t> maybe_empty, int64_t new_val) {
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:95:    TORCH_INTERNAL_ASSERT(dynamicLayerStack.empty() || getSingleLevelAutogradFunctionAllowed(),
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:104:        dynamicLayerStack.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:109:    TORCH_CHECK(dynamicLayerStack.empty() || allow_inplace_requires_grad_,
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:118:    TORCH_CHECK(dynamicLayerStack.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/MatrixRef.h:56:  bool empty() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/xnnpack/Pooling.h:30:        !parameter.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:202:    TORCH_CHECK(opt_dim.has_value() && !opt_dim->empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOpsUtils.h:280:    !dim.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/MathBitsFallback.h:109:          TORCH_CHECK(mutable_inputs_with_their_clones.empty(), op_name, " fallback does not support operators with more than one mutable tensors with ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:781:        at::empty(self.values().sizes(), options.layout(kStrided)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:791:        at::empty(self.values().sizes(), options.layout(kStrided)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:801:        at::empty(self.values().sizes(), options.layout(kStrided)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:812:        at::empty(self.values().sizes(), options.layout(kStrided)),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/StructuredSparseLinearCUTLASS.cu:248:            tensor_a.new_empty({length_m, length_n},
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorMath.cpp:776:      !proposed_shape.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorMath.cpp:863:      !proposed_shape.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:169:      ? at::empty({0}, options.dtype(at::ScalarType::Long))
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BatchLinearAlgebraKernel.cpp:347:  // and (batch_size - 1) calls to allocate and deallocate workspace using at::empty()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BatchLinearAlgebraKernel.cpp:423:  // and (batch_size - 1) calls to allocate and deallocate workspace using at::empty()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:394:    // TODO: dedupe this with empty() symbolic logic
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2666:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2696:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2719:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2729:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2739:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2746:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2753:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2759:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2823:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:2831:  TORCH_CHECK(!tensors.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:3385:  TORCH_CHECK(!positions.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/linalg/BatchLinearAlgebra.cpp:1908:  // and (batch_size - 1) calls to allocate and deallocate workspace using at::empty()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/SpectralOps.cpp:401:    while (!sorted_dims.empty()) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Indexing.cu:438:  TORCH_CHECK(!indices.empty() || is_expandable_to(value.sizes(), self.sizes()), "shape mismatch: value tensor of shape ", value.sizes(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:421:  TORCH_CHECK(!output_sizes.empty())
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/QnnpackUtils.h:500:    at::empty(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/attention_backward.cu:271:        ? at::empty({B, nH, M}, query.options().dtype(at::ScalarType::Float))
   - /home/haozhe/code/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:19:          at::empty(
   - /home/haozhe/code/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:25:          at::empty(
   - /home/haozhe/code/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:31:          at::empty(
   - /home/haozhe/code/pytorch/aten/src/ATen/record_function.h:261:  bool empty() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/SparseTensorImpl.cpp:32:      , at::empty({1, 0}, at::initialTensorOptions().device(sparseTensorSetToDeviceType(key_set)).dtype(ScalarType::Long))
   - /home/haozhe/code/pytorch/aten/src/ATen/SparseTensorImpl.cpp:33:      , at::empty({0}, at::initialTensorOptions().device(sparseTensorSetToDeviceType(key_set)).dtype(data_type))) {}
   - /home/haozhe/code/pytorch/aten/src/ATen/MapAllocator.cpp:67:  : filename_(filename.empty() ? unknown_filename : std::move(filename))
   - /home/haozhe/code/pytorch/aten/src/ATen/MapAllocator.cpp:73:  , eventname_(filename.empty() ? unknown_eventname : (filename + "_event"))
   - /home/haozhe/code/pytorch/aten/src/ATen/core/class_type.cpp:155:        input_tuple_types.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/core/List_inl.h:224:bool List<T>::empty() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/Dict_inl.h:104:bool Dict<Key, Value>::empty() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/function_schema.cpp:84:  while (!typeStack.empty()) {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/Dict.h:272:  bool empty() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/core/boxing/impl/boxing.h:235:          stack.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/core/type.cpp:1036:  while (!to_scan.empty()) {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/List.h:337:  bool empty() const;
   - /home/haozhe/code/pytorch/aten/src/ATen/core/ivalue_inl.h:528:  C10_NODISCARD bool empty() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/ivalue_inl.h:1343:        excessDevices.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/core/IListRef.h:556:  bool empty() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/TensorIterator.cpp:1653:  while (!vec.empty() && !vec.back()->can_use_32bit_indexing()) {
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.cpp:162:        !names.empty(),
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.cpp:306:  TORCH_CHECK(!self_names.empty() && !other_names.empty(),
  - empty_cpu(CPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.h:59:TORCH_API TensorBase empty_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.h:65:TORCH_API TensorBase empty_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:254:Tensor empty_cpu(IntArrayRef size, c10::optional<ScalarType> dtype_opt, c10::optional<Layout> layout_opt,
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.cpp:232:TensorBase empty_cpu(IntArrayRef size, ScalarType dtype, bool pin_memory,
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.cpp:239:TensorBase empty_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.cpp:254:TensorBase empty_cpu(
  - empty_cuda(CUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/TensorFactories.cu:53:Tensor empty_cuda(IntArrayRef size, c10::optional<ScalarType> dtype_opt, c10::optional<Layout> layout_opt, c10::optional<Device> device_opt, c10::optional<bool> pin_memory_opt, c10::optional<c10::MemoryFormat> memory_format_opt) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Nonzero.cu:81:      Tensor(at::detail::empty_cuda({self.dim(), num_nonzeros_h}, out.options())) :
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.h:7:TORCH_CUDA_CPP_API TensorBase empty_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.h:13:TORCH_CUDA_CPP_API TensorBase empty_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.h:21:TORCH_CUDA_CPP_API TensorBase empty_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.cpp:9:TensorBase empty_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.cpp:24:TensorBase empty_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.cpp:38:TensorBase empty_cuda(
  - empty_mps(MPS)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mps/TensorFactory.cpp:65:Tensor empty_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.h:9:C10_EXPORT TensorBase empty_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.h:16:C10_EXPORT TensorBase empty_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.cpp:20:TensorBase empty_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.cpp:78:TensorBase empty_mps(
  - empty_meta_symint(Meta)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/MetaTensor.cpp:15:Tensor empty_meta_symint(
  - empty_mkldnn(MkldnnCPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorFactories.cpp:15:Tensor empty_mkldnn(IntArrayRef sizes, c10::optional<ScalarType> dtype, c10::optional<Layout> layout, c10::optional<Device> device, c10::optional<bool> pin_memory, c10::optional<c10::MemoryFormat> optional_memory_format) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mkldnn/TensorFactories.cpp:29:Tensor empty_mkldnn(IntArrayRef sizes, c10::optional<ScalarType> dtype, c10::optional<Layout> layout, c10::optional<Device> device, c10::optional<bool> pin_memory, c10::optional<c10::MemoryFormat> optional_memory_format) {
  - empty_sparse(SparseCPU, SparseCUDA, SparseMeta)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseTensor.cpp:213:Tensor empty_sparse(
  - empty_sparse_compressed(SparseCsrCPU, SparseCsrCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensor.cpp:558:Tensor empty_sparse_compressed(
  - empty_unknown_quantized(QuantizedCPU, QuantizedCUDA, QuantizedMeta)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorFactories.cpp:71:Tensor empty_unknown_quantized(


 - empty_strided
  - empty_strided
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:681:  // with `size` and `stride` via empty_strided(size, stride).
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:691:        "new_empty_strided(sizes, strides): dimensionality of sizes (",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Factory.cpp:45:Tensor empty_strided(
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1042:  // with `size` and `stride` via empty_strided(size, stride).
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1052:        "new_empty_strided(sizes, strides): dimensionality of sizes (",
  - empty_strided_cpu(CPU)
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.h:75:TORCH_API TensorBase empty_strided_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.h:81:TORCH_API TensorBase empty_strided_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.h:89:TORCH_API TensorBase empty_strided_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorFactories.cpp:321:Tensor empty_strided_cpu(IntArrayRef size, IntArrayRef stride, c10::optional<ScalarType> dtype_opt,
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.cpp:265:TensorBase empty_strided_cpu(IntArrayRef size, IntArrayRef stride,
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.cpp:273:TensorBase empty_strided_cpu(
   - /home/haozhe/code/pytorch/aten/src/ATen/EmptyTensor.cpp:288:TensorBase empty_strided_cpu(
  - empty_strided_cuda(CUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/TensorFactories.cu:74:Tensor empty_strided_cuda(IntArrayRef size, IntArrayRef stride, c10::optional<ScalarType> dtype_opt, c10::optional<Layout> layout_opt, c10::optional<Device> device_opt, c10::optional<bool> pin_memory_opt) {
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.h:25:TORCH_CUDA_CPP_API TensorBase empty_strided_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.h:31:TORCH_CUDA_CPP_API TensorBase empty_strided_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.h:39:TORCH_CUDA_CPP_API TensorBase empty_strided_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.cpp:49:TensorBase empty_strided_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.cpp:64:TensorBase empty_strided_cuda(
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/EmptyTensor.cpp:78:TensorBase empty_strided_cuda(
  - empty_strided_mps(MPS)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/mps/TensorFactory.cpp:76:Tensor empty_strided_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.h:19:C10_EXPORT TensorBase empty_strided_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.h:25:C10_EXPORT TensorBase empty_strided_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.cpp:89:TensorBase empty_strided_mps(
   - /home/haozhe/code/pytorch/aten/src/ATen/mps/EmptyTensor.cpp:116:TensorBase empty_strided_mps(
  - empty_strided_meta_symint(Meta)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/MetaTensor.cpp:44:Tensor empty_strided_meta_symint(
  - empty_strided_unknown_quantized(QuantizedCPU, QuantizedCUDA)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/TensorFactories.cpp:93:Tensor empty_strided_unknown_quantized(


 - eq.Scalar
  - eq
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:517:  Vectorized<ComplexDbl> eq(const Vectorized<ComplexDbl>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:542:  Vectorized<ComplexFlt> eq(const Vectorized<ComplexFlt>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:670:  Vectorized<float> eq(const Vectorized<float>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:777:inline Vectorized<float> Vectorized<float>::eq(const Vectorized<float>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:156:  Vectorized<int64_t> eq(const Vectorized<int64_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:274:  Vectorized<int32_t> eq(const Vectorized<int32_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:488:  Vectorized<int16_t> eq(const Vectorized<int16_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:763:  Vectorized<int8_t> eq(const Vectorized<int8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:803:  Vectorized<uint8_t> eq(const Vectorized<uint8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1152:inline Vectorized<int64_t> Vectorized<int64_t>::eq(const Vectorized<int64_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1176:inline Vectorized<int32_t> Vectorized<int32_t>::eq(const Vectorized<int32_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1200:inline Vectorized<int16_t> Vectorized<int16_t>::eq(const Vectorized<int16_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1224:inline Vectorized<int8_t> Vectorized<int8_t>::eq(const Vectorized<int8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1248:inline Vectorized<uint8_t> Vectorized<uint8_t>::eq(const Vectorized<uint8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:364:  Vectorized<c10::complex<float>> eq(const Vectorized<c10::complex<float>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:483:inline Vectorized<c10::complex<float>> Vectorized<c10::complex<float>>::eq(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:597:  Vectorized<BFloat16> eq(const Vectorized<BFloat16>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:627:inline Vectorized<BFloat16> Vectorized<BFloat16>::eq(const Vectorized<BFloat16>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:795:  Vectorized<Half> eq(const Vectorized<Half>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:825:inline Vectorized<Half> Vectorized<Half>::eq(const Vectorized<Half>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:801:        vec_cmpeq(_vec0, other._vec0), vec_cmpeq(_vec1, other._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:806:        vec_cmpeq(_vec0, other._vec0), vec_cmpeq(_vec1, other._vec1)}
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:828:  Vectorized<T> C10_ALWAYS_INLINE eq(const Vectorized<T>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1882:  Vectorized<T> C10_ALWAYS_INLINE eq(const Vectorized<T>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2377:  Vectorized<T> C10_ALWAYS_INLINE eq(const Vectorized<T>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:293:  Vectorized<double> eq(const Vectorized<double>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:376:inline Vectorized<double> Vectorized<double>::eq(const Vectorized<double>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:328:  Vectorized<float> eq(const Vectorized<float>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:411:inline Vectorized<float> Vectorized<float>::eq(const Vectorized<float>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:331:  Vectorized<c10::complex<double>> eq(const Vectorized<c10::complex<double>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:448:inline Vectorized<c10::complex<double>> Vectorized<c10::complex<double>>::eq(const Vectorized<c10::complex<double>>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:164:  Vectorized<int64_t> eq(const Vectorized<int64_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:312:  Vectorized<int32_t> eq(const Vectorized<int32_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:544:  Vectorized<int16_t> eq(const Vectorized<int16_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:847:  Vectorized<int8_t> eq(const Vectorized<int8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:896:  Vectorized<uint8_t> eq(const Vectorized<uint8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1192:inline Vectorized<int64_t> Vectorized<int64_t>::eq(const Vectorized<int64_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1216:inline Vectorized<int32_t> Vectorized<int32_t>::eq(const Vectorized<int32_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1240:inline Vectorized<int16_t> Vectorized<int16_t>::eq(const Vectorized<int16_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1264:inline Vectorized<int8_t> Vectorized<int8_t>::eq(const Vectorized<int8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1288:inline Vectorized<uint8_t> Vectorized<uint8_t>::eq(const Vectorized<uint8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:704:  Vectorized<BFloat16> eq(const Vectorized<BFloat16>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:734:inline Vectorized<BFloat16> Vectorized<BFloat16>::eq(const Vectorized<BFloat16>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:914:  Vectorized<Half> eq(const Vectorized<Half>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:945:inline Vectorized<Half> Vectorized<Half>::eq(const Vectorized<Half>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:396:  Vectorized<c10::complex<double>> eq(const Vectorized<c10::complex<double>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:528:inline Vectorized<c10::complex<double>> Vectorized<c10::complex<double>>::eq(const Vectorized<c10::complex<double>>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:897:  Vectorized<c10::complex<float>> eq(const Vectorized<c10::complex<float>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:1032:inline Vectorized<c10::complex<float>> Vectorized<c10::complex<float>>::eq(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:369:  Vectorized<float> eq(const Vectorized<float>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:458:inline Vectorized<float> Vectorized<float>::eq(const Vectorized<float>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:325:  Vectorized<double> eq(const Vectorized<double>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:414:inline Vectorized<double> Vectorized<double>::eq(const Vectorized<double>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SpectralOps.cpp:719:Tensor fft_fftfreq(int64_t n, double d,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SpectralOps.cpp:740:Tensor fft_rfftfreq(int64_t n, double d,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SobolEngineOpsUtils.h:32:inline int64_t bitsubseq(const int64_t n, const int64_t pos, const int64_t length) {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/ivalue.h:262:   * `torch.eq()`)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/pow_test.cpp:91:void assert_eq(T val, T act, T exp) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/pow_test.cpp:100:void assert_eq(T val, T act, T exp) {
  - eq_quantized_cpu(QuantizedCPU)


 - eq.Tensor
  - eq
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:517:  Vectorized<ComplexDbl> eq(const Vectorized<ComplexDbl>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:542:  Vectorized<ComplexFlt> eq(const Vectorized<ComplexFlt>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:670:  Vectorized<float> eq(const Vectorized<float>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:777:inline Vectorized<float> Vectorized<float>::eq(const Vectorized<float>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:156:  Vectorized<int64_t> eq(const Vectorized<int64_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:274:  Vectorized<int32_t> eq(const Vectorized<int32_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:488:  Vectorized<int16_t> eq(const Vectorized<int16_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:763:  Vectorized<int8_t> eq(const Vectorized<int8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:803:  Vectorized<uint8_t> eq(const Vectorized<uint8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1152:inline Vectorized<int64_t> Vectorized<int64_t>::eq(const Vectorized<int64_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1176:inline Vectorized<int32_t> Vectorized<int32_t>::eq(const Vectorized<int32_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1200:inline Vectorized<int16_t> Vectorized<int16_t>::eq(const Vectorized<int16_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1224:inline Vectorized<int8_t> Vectorized<int8_t>::eq(const Vectorized<int8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_int.h:1248:inline Vectorized<uint8_t> Vectorized<uint8_t>::eq(const Vectorized<uint8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:364:  Vectorized<c10::complex<float>> eq(const Vectorized<c10::complex<float>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:483:inline Vectorized<c10::complex<float>> Vectorized<c10::complex<float>>::eq(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:597:  Vectorized<BFloat16> eq(const Vectorized<BFloat16>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:627:inline Vectorized<BFloat16> Vectorized<BFloat16>::eq(const Vectorized<BFloat16>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:795:  Vectorized<Half> eq(const Vectorized<Half>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:825:inline Vectorized<Half> Vectorized<Half>::eq(const Vectorized<Half>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:801:        vec_cmpeq(_vec0, other._vec0), vec_cmpeq(_vec1, other._vec1)};
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:806:        vec_cmpeq(_vec0, other._vec0), vec_cmpeq(_vec1, other._vec1)}
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:828:  Vectorized<T> C10_ALWAYS_INLINE eq(const Vectorized<T>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1882:  Vectorized<T> C10_ALWAYS_INLINE eq(const Vectorized<T>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2377:  Vectorized<T> C10_ALWAYS_INLINE eq(const Vectorized<T>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:293:  Vectorized<double> eq(const Vectorized<double>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:376:inline Vectorized<double> Vectorized<double>::eq(const Vectorized<double>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:328:  Vectorized<float> eq(const Vectorized<float>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:411:inline Vectorized<float> Vectorized<float>::eq(const Vectorized<float>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:331:  Vectorized<c10::complex<double>> eq(const Vectorized<c10::complex<double>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:448:inline Vectorized<c10::complex<double>> Vectorized<c10::complex<double>>::eq(const Vectorized<c10::complex<double>>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:164:  Vectorized<int64_t> eq(const Vectorized<int64_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:312:  Vectorized<int32_t> eq(const Vectorized<int32_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:544:  Vectorized<int16_t> eq(const Vectorized<int16_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:847:  Vectorized<int8_t> eq(const Vectorized<int8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:896:  Vectorized<uint8_t> eq(const Vectorized<uint8_t>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1192:inline Vectorized<int64_t> Vectorized<int64_t>::eq(const Vectorized<int64_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1216:inline Vectorized<int32_t> Vectorized<int32_t>::eq(const Vectorized<int32_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1240:inline Vectorized<int16_t> Vectorized<int16_t>::eq(const Vectorized<int16_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1264:inline Vectorized<int8_t> Vectorized<int8_t>::eq(const Vectorized<int8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_int.h:1288:inline Vectorized<uint8_t> Vectorized<uint8_t>::eq(const Vectorized<uint8_t>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:704:  Vectorized<BFloat16> eq(const Vectorized<BFloat16>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:734:inline Vectorized<BFloat16> Vectorized<BFloat16>::eq(const Vectorized<BFloat16>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:914:  Vectorized<Half> eq(const Vectorized<Half>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:945:inline Vectorized<Half> Vectorized<Half>::eq(const Vectorized<Half>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:396:  Vectorized<c10::complex<double>> eq(const Vectorized<c10::complex<double>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:528:inline Vectorized<c10::complex<double>> Vectorized<c10::complex<double>>::eq(const Vectorized<c10::complex<double>>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:897:  Vectorized<c10::complex<float>> eq(const Vectorized<c10::complex<float>>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:1032:inline Vectorized<c10::complex<float>> Vectorized<c10::complex<float>>::eq(
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:369:  Vectorized<float> eq(const Vectorized<float>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:458:inline Vectorized<float> Vectorized<float>::eq(const Vectorized<float>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:325:  Vectorized<double> eq(const Vectorized<double>& other) const;
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:414:inline Vectorized<double> Vectorized<double>::eq(const Vectorized<double>& other) const {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SpectralOps.cpp:719:Tensor fft_fftfreq(int64_t n, double d,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SpectralOps.cpp:740:Tensor fft_rfftfreq(int64_t n, double d,
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SobolEngineOpsUtils.h:32:inline int64_t bitsubseq(const int64_t n, const int64_t pos, const int64_t length) {
   - /home/haozhe/code/pytorch/aten/src/ATen/core/ivalue.h:262:   * `torch.eq()`)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/pow_test.cpp:91:void assert_eq(T val, T act, T exp) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/pow_test.cpp:100:void assert_eq(T val, T act, T exp) {
  - eq_quantized_cpu(QuantizedCPU)


 - erf
  - erf
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:497:  Vectorized<ComplexDbl> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:576:  Vectorized<ComplexFlt> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:234:  Vectorized<double> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:276:  Vectorized<float> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:391:  Vectorized<float> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:253:  Vectorized<c10::complex<float>> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:334:  Vectorized<T> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1049:  Vectorized<T> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:152:  Vectorized<double> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:158:  Vectorized<float> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:220:  Vectorized<c10::complex<double>> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:387:  Vectorized<T> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:417:  Vectorized<T> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:281:  Vectorized<c10::complex<double>> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:784:  Vectorized<c10::complex<float>> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:187:  Vectorized<float> erf() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:172:  Vectorized<double> erf() const {
  - erf_sparse(SparseCPU, SparseCUDA)
  - erf_sparse_csr(SparseCsrCPU, SparseCsrCUDA)


 - exp
  - exp
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_double_vsx.h:453:  Vectorized<ComplexDbl> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_complex_float_vsx.h:532:  Vectorized<ComplexFlt> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_double_vsx.h:240:  Vectorized<double> C10_ALWAYS_INLINE exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vsx/vec256_float_vsx.h:303:  Vectorized<float> C10_ALWAYS_INLINE exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float_neon.h:406:  Vectorized<float> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:259:  Vectorized<c10::complex<float>> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_float.h:260:    //exp(a + bi)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_bfloat16.h:354:  Vectorized<T> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:1056:  Vectorized<T> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/zarch/vec256_zarch.h:2422:  Vectorized<T> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_double.h:161:  Vectorized<double> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:179:    // - exp(- x * x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_float.h:196:  Vectorized<float> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:226:  Vectorized<c10::complex<double>> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec256/vec256_complex_double.h:227:    //exp(a + bi)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec_base.h:396:  Vectorized<T> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_bfloat16.h:437:  Vectorized<T> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:287:  Vectorized<c10::complex<double>> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_double.h:288:    //exp(a + bi)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:790:  Vectorized<c10::complex<float>> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_complex_float.h:791:    //exp(a + bi)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:208:    // - exp(- x * x)
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_float.h:225:  Vectorized<float> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/cpu/vec/vec512/vec512_double.h:181:  Vectorized<double> exp() const {
   - /home/haozhe/code/pytorch/aten/src/ATen/NumericUtils.h:96:C10_HOST_DEVICE inline T exp(T x) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:930:              m0 + (a0 - b0).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:934:              m1 + (a1 - b1).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/BinaryOpsKernel.cpp:963:                m + (a - b).abs().neg().exp().log1p(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Activation.cpp:1096:            : static_cast<scalar_t>(std::log1p(std::exp(a * beta))) / beta;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Activation.cpp:1261:              x_vec0 / (kOneVec + x_vec0.neg().exp()),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Activation.cpp:1337:            x_vec0 * x_vec0.exp().log1p().tanh(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/Activation.cpp:1338:            x_vec1 * x_vec1.exp().log1p().tanh()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:176:      // map (x - max).exp() and reduce to sum
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:526:          // compute grad_output - output.exp() * sum
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:544:                  std::exp(output_ptr[d2]) * tmp_sum_data[d2];
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:629:          // compute grad_output - output.exp() * sum
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:650:                  grad_output_fvec0 - output_fvec0.exp() * sum_fvec0;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:652:                  grad_output_fvec1 - output_fvec1.exp() * sum_fvec1;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:659:                  std::exp(float(output_ptr[d2])) * tmp_sum_data[d2];
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:942:      // compute sum of (x - max).exp()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/SoftMaxKernel.cpp:1062:      // compute sum of (x - max).exp()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/avx_mathfun.h:183:  /* express exp(x) as exp(g + n*log(2)) */
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/LogAddExp.h:46:      // handle the -inf case, the imaginary part here does not really matter as the exp(value)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/SoftMax.cpp:325:                  std::exp(output_data[d * dim_stride]) * sum;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2618:Tensor linalg_matrix_exp(const Tensor& a) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2636:Tensor matrix_exp(const Tensor& a) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:222:                       exp(14 - maxX_0[3]) / (exp(14 - maxX_0[3]) + exp(24 - maxX_0[3])),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:223:                       exp(15 - maxX_0[4]) / exp(15 - maxX_0[4]),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:224:                       exp(22 - maxX_0[1]) / exp(22 - maxX_0[1]),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:225:                       exp(24 - maxX_0[3]) / (exp(14 - maxX_0[3]) + exp(24 - maxX_0[3]))]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:231:                       exp(14 - maxX_1[0]) / (exp(11 - maxX_1[0]) + exp(14 - maxX_1[0]) + exp(15 - maxX_1[0])),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:232:                       exp(15 - maxX_1[0]) / (exp(11 - maxX_1[0]) + exp(14 - maxX_1[0]) + exp(15 - maxX_1[0])),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:233:                       exp(22 - maxX_1[1]) / (exp(22 - maxX_1[1]) + exp(24 - maxX_1[1])),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:234:                       exp(24 - maxX_1[1]) / (exp(22 - maxX_1[1]) + exp(24 - maxX_1[1]))]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:236:                       exp(-1) / (exp(-4) + exp(-1) + 1),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:237:                       1 / (exp(-4) + exp(-1) + 1),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:238:                       exp(-2) / (exp(-2) + 1),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:239:                       1 / (exp(-2) + 1)]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:280:                       exp(14 - mx_0[pool_0[1]]) / exp_sum_0[pool_0[1]]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:281:                       exp(15 - mx_0[pool_0[2]]) / exp_sum_0[pool_0[2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:282:                       exp(22 - mx_0[pool_0[3]]) / exp_sum_0[pool_0[3]]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SoftMax.cpp:283:                       exp(24 - mx_0[pool_0[4]]) / exp_sum_0[pool_0[4]]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/SoftMax.cu:211:                c10::cuda::compat::exp(out_values_row[k]) * tmp_row;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/cuda/SoftMax.cu:219:                c10::cuda::compat::exp(out_values_row[k]) * tmp_row;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/UnaryOps.cpp:944:std::tuple<Tensor, Tensor> frexp(const Tensor& self) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/UnaryOps.cpp:960:              "torch.frexp() expects mantissa to have dtype ", self.dtype(),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/UnaryOps.cpp:963:              "torch.frexp() expects exponent to have int dtype "
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:494:      std::exp(std::lgamma(static_cast<scalar_t>(n) + one)) *
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:615:  // compute x^a * exp(-a) / gamma(a)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:616:  // corrected from (15) and (16) in [igam2] by replacing exp(x - a) with
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:617:  // exp(a - x).
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:1307:  /* Chebyshev coefficients for exp(-x) I0(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:1333:  /* Chebyshev coefficients for exp(-x) sqrt(x) I0(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:1359:  /* Chebyshev coefficients for exp(-x) I1(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:1386:  /* Chebyshev coefficients for exp(-x) I1(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:1415:  /* Chebyshev coefficients for exp(-x) sqrt(x) I1(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Math.h:1441:  /* Chebyshev coefficients for exp(-x) sqrt(x) I1(x)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/LogcumsumexpKernel.cu:48:__host__ __device__ c10::complex<scalar_t> _fast_build_exp(const c10::complex<scalar_t>& x) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/LogcumsumexpKernel.cu:86:      // handle the -inf case, the imaginary part here does not really matter as the exp(value)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/LossCTC.cu:471:              -std::exp(log_alpha_data[la_batch_offset + la_input_stride * t + la_target_stride * (s*2+1)]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ActivationSoftplusKernel.cu:39:              : (::log1p(std::exp(aop * beta))) / beta;
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/IGammaKernel.cu:123:  // compute x^a * exp(-a) / gamma(a)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/IGammaKernel.cu:124:  // corrected from (15) and (16) in [igam2] by replacing exp(x - a) with
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/IGammaKernel.cu:125:  // exp(a - x).
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ActivationEluKernel.cu:75:                    ? aop * negiptcoef * negcoef * std::exp(bop * negiptcoef)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/ActivationGeluKernel.cu:79:                c10::cuda::compat::exp(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/softargmax-operator-tester.h:131:              exp((int32_t(input[i * inputStride() + c]) - maxInput) *
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/softargmax-operator-tester.h:136:              exp((int32_t(input[i * inputStride() + c]) - maxInput) *
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:454:Tensor logcumsumexp(const Tensor& self, int64_t dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:1394:              "logsumexp(): Expected floating point type for result tensor, but got: ",
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:1410:Tensor logsumexp(const Tensor& self, IntArrayRef dims, bool keepdim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:1423:Tensor logsumexp(const Tensor& self, DimnameList dims, bool keepdim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:1432:Tensor special_logsumexp(const Tensor& self, IntArrayRef dims, bool keepdim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:2013:Tensor logcumsumexp(const Tensor& self, Dimname dim) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:851:      // Also does accum[i] <- exp(accum[i] - mi)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:1136:        (a) accum   <- exp(accum - mi)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_forward.h:1137:        (b) m_prime <- exp(m_prime - mi)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_backward.h:302:    -1)).exp() # epilogue
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernel_backward.h:1578:      // logsumexp[i_start:i_end].unsqueeze(1)).exp()
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/softmax.h:221:    inline __device__ void apply_exp(const float (&max)[MMAS_M * 2]) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/softmax.h:224:            // Instead of computing exp(x - max), we compute exp2(x * log_2(e) -
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/softmax.h:240:    inline __device__ void scale_apply_exp(const float (&max)[MMAS_M * 2], const float scale_) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/flash_attn/softmax.h:245:            // Instead of computing exp(x - max), we compute exp2(x * log_2(e) -
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BinaryOps.cpp:1560:Tensor ldexp(const Tensor& self, const Tensor& other) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:812:        : additionalInfo(info), testSeed(seed), exp(expected), act(actual), arg0(input0), argSize(1)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:816:        : additionalInfo(info), testSeed(seed), exp(expected), act(actual), arg0(input0), arg1(input1), argSize(2)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:820:        : additionalInfo(info), testSeed(seed), exp(expected), act(actual), arg0(input0), arg1(input1), arg2(input2), argSize(3)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:823:    AssertVectorized(const std::string& info, TestSeed seed, const T& expected, const T& actual) : additionalInfo(info), testSeed(seed), exp(expected), act(actual)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vec_test_all_types.h:826:    AssertVectorized(const std::string& info, const T& expected, const T& actual) : additionalInfo(info), exp(expected), act(actual), hasSeed(false)
   - /home/haozhe/code/pytorch/aten/src/ATen/cuda/llvm_complex.cpp:825:exp(const complex<_Tp>& __x)


 - expand
  - expand
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesViews.cpp:467:  // As an example, let B0 be a batch dimension and consider expand(Tensor[B0, 3], [2, 3]).
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:291:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:299:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:308:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:590:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:598:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:607:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:950:  TensorDescriptor bdesc{grad_bias->expand({1, grad_bias->size(0)}),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Expand.cpp:21:Tensor expand(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2141:        .expand(a_sizes_minus_last)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2081:                        .expand(perm_sizes)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1103:Tensor expand(const Tensor& self, c10::IntArrayRef size, bool /*unused*/) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1256:      .expand({batch_numel_nonzero})
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1821:          blocksize_arange_0.unsqueeze(-1).expand({-1, blocksize[1]}),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1822:          blocksize_arange_1.unsqueeze(0).expand({blocksize[0], -1})
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Blas.cpp:152:  // expand().
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/attention_backward.cu:358:        // torch.tensor((B * nH, 1, nK)).expand((B * nH, nQ, nK)),
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.h:118:TORCH_API void propagate_names_for_expand(
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vulkan_api_test.cpp:1835:void test_expand(const at::IntArrayRef input_shape, const at::IntArrayRef output_shape) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/broadcast_test.cpp:55:      a.expand(expanded_sizes) + b.expand(expanded_sizes) +
   - /home/haozhe/code/pytorch/aten/src/ATen/test/broadcast_test.cpp:66:      aTensorScalar.expand(expanded_sizes)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/scalar_tensor_test.cpp:32:bool should_expand(const IntArrayRef &from_size, const IntArrayRef &to_size) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:937:          x.permute({1, 3, 0, 2}).view({B0, 1, B2, 1, 2, 3}).expand({B0, B1, B2, B3, 2, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:938:          y.permute({2, 0, 1}).view({1, B1, 1, B3, 3}).expand({B0, B1, B2, B3, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1068:          at::movedim(x, {1, 3}, {0, 1}).view({B0, B1, 1, 2, 3}).expand({B0, B1, B2, 2, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1069:          y.view({1, B1, 1, 4}).expand({B0, B1, B2, 4}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1070:          z.t().view({1, 1, B2, 2}).expand({B0, B1, B2, 2}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1085:          x.view({1, 1, 1, 2, 3}).expand({B0, B1, B2, 2, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1086:          y.t().view({B0, 1, 1, 4}).expand({B0, B1, B2, 4}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1087:          z.permute({0, 2, 1}).view({1, B1, B2, 2}).expand({B0, B1, B2, 2}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/native_test.cpp:162:          .bmm(d1.view({1, 3, 1}).expand({24, 3, 1}))
   - /home/haozhe/code/pytorch/aten/src/ATen/test/native_test.cpp:182:                        .bmm(d2Acc.expand({24, 3, 4}))
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:175:  // As an example, let B0 be a batch dimension and consider expand(Tensor[B0, 3], [2, 3]).
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:140:      c10::MaybeOwned<Tensor>::owned(to_expand1.expand(tensor.sizes())),
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:199:      c10::MaybeOwned<Tensor>::owned(to_expand1.expand(expanded_size)),
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:256:      c10::MaybeOwned<Tensor>::owned(to_expand1.expand(expanded_size)),
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:257:      c10::MaybeOwned<Tensor>::owned(to_expand2.expand(expanded_size)),
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.cpp:382:void propagate_names_for_expand(const Tensor& result, const Tensor& self) {
  - expand(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesViews.cpp:467:  // As an example, let B0 be a batch dimension and consider expand(Tensor[B0, 3], [2, 3]).
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:291:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:299:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:308:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:590:    // batched_indices: [arange(B).expand(B, 2, 2), :, Tensor[B, 2, 2], :, Tensor[2, 2]]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:598:    // batched_indices: [arange(B).expand(B, 2, 2), Tensor[B, 2, 2], Tensor[2, 2], :, :]
   - /home/haozhe/code/pytorch/aten/src/ATen/functorch/BatchRulesScatterOps.cpp:607:  // batched_indices: [arange(B).expand(B, 2, 3), :, :, Tensor[B, 2, 3], Tensor[2, 3], :]
   - /home/haozhe/code/pytorch/aten/src/ATen/native/miopen/Conv_miopen.cpp:950:  TensorDescriptor bdesc{grad_bias->expand({1, grad_bias->size(0)}),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/vulkan/ops/Expand.cpp:21:Tensor expand(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/LinearAlgebra.cpp:2141:        .expand(a_sizes_minus_last)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2081:                        .expand(perm_sizes)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorShape.cpp:1103:Tensor expand(const Tensor& self, c10::IntArrayRef size, bool /*unused*/) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1256:      .expand({batch_numel_nonzero})
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1821:          blocksize_arange_0.unsqueeze(-1).expand({-1, blocksize[1]}),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1822:          blocksize_arange_1.unsqueeze(0).expand({blocksize[0], -1})
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/Blas.cpp:152:  // expand().
   - /home/haozhe/code/pytorch/aten/src/ATen/native/transformers/cuda/attention_backward.cu:358:        // torch.tensor((B * nH, 1, nK)).expand((B * nH, nQ, nK)),
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.h:118:TORCH_API void propagate_names_for_expand(
   - /home/haozhe/code/pytorch/aten/src/ATen/test/vulkan_api_test.cpp:1835:void test_expand(const at::IntArrayRef input_shape, const at::IntArrayRef output_shape) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/broadcast_test.cpp:55:      a.expand(expanded_sizes) + b.expand(expanded_sizes) +
   - /home/haozhe/code/pytorch/aten/src/ATen/test/broadcast_test.cpp:66:      aTensorScalar.expand(expanded_sizes)
   - /home/haozhe/code/pytorch/aten/src/ATen/test/scalar_tensor_test.cpp:32:bool should_expand(const IntArrayRef &from_size, const IntArrayRef &to_size) {
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:937:          x.permute({1, 3, 0, 2}).view({B0, 1, B2, 1, 2, 3}).expand({B0, B1, B2, B3, 2, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:938:          y.permute({2, 0, 1}).view({1, B1, 1, B3, 3}).expand({B0, B1, B2, B3, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1068:          at::movedim(x, {1, 3}, {0, 1}).view({B0, B1, 1, 2, 3}).expand({B0, B1, B2, 2, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1069:          y.view({1, B1, 1, 4}).expand({B0, B1, B2, 4}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1070:          z.t().view({1, 1, B2, 2}).expand({B0, B1, B2, 2}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1085:          x.view({1, 1, 1, 2, 3}).expand({B0, B1, B2, 2, 3}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1086:          y.t().view({B0, 1, 1, 4}).expand({B0, B1, B2, 4}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/legacy_vmap_test.cpp:1087:          z.permute({0, 2, 1}).view({1, B1, B2, 2}).expand({B0, B1, B2, 2}),
   - /home/haozhe/code/pytorch/aten/src/ATen/test/native_test.cpp:162:          .bmm(d1.view({1, 3, 1}).expand({24, 3, 1}))
   - /home/haozhe/code/pytorch/aten/src/ATen/test/native_test.cpp:182:                        .bmm(d2Acc.expand({24, 3, 4}))
   - /home/haozhe/code/pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:175:  // As an example, let B0 be a batch dimension and consider expand(Tensor[B0, 3], [2, 3]).
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:140:      c10::MaybeOwned<Tensor>::owned(to_expand1.expand(tensor.sizes())),
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:199:      c10::MaybeOwned<Tensor>::owned(to_expand1.expand(expanded_size)),
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:256:      c10::MaybeOwned<Tensor>::owned(to_expand1.expand(expanded_size)),
   - /home/haozhe/code/pytorch/aten/src/ATen/ExpandUtils.h:257:      c10::MaybeOwned<Tensor>::owned(to_expand2.expand(expanded_size)),
   - /home/haozhe/code/pytorch/aten/src/ATen/NamedTensorUtils.cpp:382:void propagate_names_for_expand(const Tensor& result, const Tensor& self) {


 - fill.Scalar
  - fill
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistributionTemplates.h:152:void normal_fill(const TensorBase &self, const scalar_t mean, const scalar_t std, RNG generator) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Fill.cpp:75:Tensor fill(const Tensor& self, const Scalar& value) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Fill.cpp:79:Tensor fill(const Tensor& self, const Tensor& value) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:348:Tensor index_fill(const Tensor& self, Dimname dim, const Tensor& index, const Scalar& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:354:Tensor index_fill(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1478:Tensor index_fill(const Tensor & self, int64_t dim, const Tensor & index, const Scalar& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1482:Tensor index_fill(const Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1922:Tensor masked_fill(const Tensor & self, const Tensor & mask, const Scalar& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1936:Tensor masked_fill(const Tensor & self, const Tensor & mask, const Tensor & source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:214:      std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:214:Tensor NestedTensor_masked_fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1505:          std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/TensorTopK.cu:238:__global__ void fill(T* x, T value, IndexType size) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/SoftMax.cu:1107:          output.masked_fill(mask, 0),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/requantization-tester.h:255:    std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/requantization-tester.h:271:    std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:677:                               input_conj.masked_fill(~mask, 1.).cumprod(dim)
   - /home/haozhe/code/pytorch/aten/src/ATen/ScalarOps.cpp:17:Tensor& scalar_fill(Tensor& self, const Scalar& value) {
  - fill(CompositeExplicitAutograd)
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cpu/DistributionTemplates.h:152:void normal_fill(const TensorBase &self, const scalar_t mean, const scalar_t std, RNG generator) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Fill.cpp:75:Tensor fill(const Tensor& self, const Scalar& value) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/Fill.cpp:79:Tensor fill(const Tensor& self, const Tensor& value) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:348:Tensor index_fill(const Tensor& self, Dimname dim, const Tensor& index, const Scalar& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/NamedTensor.cpp:354:Tensor index_fill(const Tensor& self, Dimname dim, const Tensor& index, const Tensor& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1478:Tensor index_fill(const Tensor & self, int64_t dim, const Tensor & index, const Scalar& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1482:Tensor index_fill(const Tensor & self, int64_t dim, const Tensor & index, const Tensor & source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1922:Tensor masked_fill(const Tensor & self, const Tensor & mask, const Scalar& source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:1936:Tensor masked_fill(const Tensor & self, const Tensor & mask, const Tensor & source) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/sparse/SparseCsrTensorMath.cpp:214:      std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/nested/NestedTensorBinaryOps.cpp:214:Tensor NestedTensor_masked_fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/TensorConversions.cpp:1505:          std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/TensorTopK.cu:238:__global__ void fill(T* x, T value, IndexType size) {
   - /home/haozhe/code/pytorch/aten/src/ATen/native/cuda/SoftMax.cu:1107:          output.masked_fill(mask, 0),
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/requantization-tester.h:255:    std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/quantized/cpu/qnnpack/test/requantization-tester.h:271:    std::fill(
   - /home/haozhe/code/pytorch/aten/src/ATen/native/ReduceOps.cpp:677:                               input_conj.masked_fill(~mask, 1.).cumprod(dim)
   - /home/haozhe/code/pytorch/aten/src/ATen/ScalarOps.cpp:17:Tensor& scalar_fill(Tensor& self, const Scalar& value) {


